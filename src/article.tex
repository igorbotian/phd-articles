% sudo apt-get install texlive-latex-base
% sudo apt-get install texlive-fonts-extra
% sudo apt-get install texlive-latex-recommended
% sudo apt-get install texlive-lang-cyrillic

\documentclass[12pt,a4paper,oneside]{article}

\title{Робастная модель классификации и ранжирования документов при интервальных предпочтениях в обучающей выборке}
\author{Л.В. Уткин}
\date{\today}

\usepackage[utf8]{inputenc} % возможность использования Unicode-символов в исходных файлах

\usepackage{amsmath} % для поддержки расширенных математических символов
\usepackage{amsfonts} % для поддержки математических шрифтов
\usepackage{amssymb} % для поддержки расширенных математических символов
\usepackage{color} % для поддержки цвета текста, отличного от чёрного
\usepackage{datetime} % поддержка календаря и дат
\usepackage{fancyhdr} % использование собственного формата заголовков
\usepackage[T2A]{fontenc} % задание шрифта
\usepackage{geometry} % задания страничных отступов
\usepackage{graphicx} % поддержка PNG-формата в качестве иллюстраций
\usepackage[pdftex,bookmarks,unicode]{hyperref} % поддержка возможности использования ссылок в качестве гиперссылок
\usepackage{indentfirst} % отступ первого параграфа в разделе
\usepackage{setspace} % задание межстрочного интервала
\usepackage{verbatim} % скрытие "comment-окружений" из результирующего документа
\usepackage[english,russian]{babel} % поддержка переносов слов

\hypersetup{
%	bookmarkstype=none,
%	plainpages=false,
	pdftitle={Робастная модель классификации и ранжирования документов при интервальных предпочтениях в обучающей выборке},
	pdfauthor={И.Ю. Ботян, Л.В. Уткин},
	pdfsubject={Статья},
	pdfnewwindow=false,
	pdfkeywords={машина опорных векторов, классификация документов, теория Демпстера-Шефера},
	colorlinks=true,
	linkcolor=black,
	citecolor=black,
	filecolor=black,
	urlcolor=black,
	pageanchor=false} % если пакет "lastpage" импортирован, то необходимо отключить данную опцию

% задание страничных отступов
\geometry{left=2.5cm}
\geometry{right=2.0cm}
\geometry{top=2.0cm}
\geometry{bottom=2.5cm}

\onehalfspacing % задание полуторного межстрочного интервала
\setlength{\parindent}{25pt} % задание абзацного отступа в 5 символов
\setlength{\headheight}{28pt}

\begin{document}

\input{tex_definitions}
\ApplyCommonPageStyle

%======================================================================================================================

\begin{center}
\textbf{\large РОБАСТНАЯ МОДЕЛЬ КЛАССИФИКАЦИИ И РАНЖИРОВАНИЯ ДОКУМЕНТОВ ПРИ ИНТЕРВАЛЬНЫХ ПРЕДПОЧТЕНИЯХ В ОБУЧАЮЩЕЙ ВЫБОРКЕ}
\end{center}
\vspace{2em}
{\footnotesize %
\textbf{Аннотация} В статье предлагается новый подход к классификации документов на основе интервальных экспертных оценок. 
Данный подход основывается на теории свидетельств Демпстера-Шефера и модификации машины опорных векторов. 
Разработана соответствующая задача квадратичной оптимизации. 
Получена её двойственная форма, представленная в терминах множителях Лагранжа и позволяющая использовать нелинейность для построения более адекватной модели. 
Приведён иллюстрационный пример построения задачи оптимизации. 
%
}

%======================================================================================================================

\section{Введение}
\label{sec:introduction}

\par
Порядковая регрессия, которая является обобщением линейной модели регрессии, характерна тем, что зависимая переменная измеряется в порядковой шкале. 
Вместе с этим в ней рассматривается задача, которая имеет свойства, присущие классификации в целом, то есть класс $y$ является конечным множеством, в котором присутствует упорядочивание среди его элементов \reference{Herbrich2000}.
Тогда можно сказать, что, например, класс \emph{0} может соответствовать понятию ``нерелевантности'', а класс \emph{y\sub{max}}, в свою очередь, может соответствовать понятию ``наибольшей релевантности''. 
Данные классы используются в задачах классификации, когда каждый элемент заданного множества документов соотносится с тем или иным классом. 
При этом, если между самими классами задан некоторый порядок, то имеет место задача ранжирования документов. 

\par
Как правило, классы определяются \emph{экспертами}, которые также задают предпочтения между ними. 
Например, в в случае веб-документов в качестве экспертов выступают системы анализа переходов по ссылкам между ними (\emph{clickthrough data}). 
Классы и связанные с ними предпочтения формируют обучающую выборку, необходимую для дальнейшего решения задачи классификации. 

\par
Стоит отметить, что существующие на данный момент подходы к решению задачи классификации основываются на предположении о том, что экспертные оценки являются простыми, когда одному классу ставится в соответствие другой. 
Тогда как в реальности существуют ситуации, в которых проводится соответствие между двумя группами (множествами) классов. 
При этом экспертные оценки в этом случае называются \emph{интервальными}, или групповыми. 
Примером такой ситуации может являться иерархическая структура ссылок в пределах веб-сайта, когда, с точки зрения пользователя, имеет смысл отдавать предпочтение одному веб-сайту перед другим, а не отдельным ссылкам на страницы этих веб-сайтов. 

\par
В настоящий момент не существует обоснованных методов решения задачи ранжирования на основе групповых экспертных оценок. 
В статье предлагается новый подход к ранжированию документов, который позволяет работать с оценками такого рода. 
Данный подход основан на применении машины опорных векторов с использованием теории свидетельств Демпстера-Шефера. 
Разработана соответствующая задача квадратичного программирования конечной размерности. 

\par
Раздел 2 посвящён стандартной постановке задачи классификации. 
Описывается подход, основанный на применении разделяющий функции, параметры которой определяются с помощью эмпирического функционала риска. 
В разделе 3 приводится задача классификации на основе попарного обучения ранжированию, которая сводится к поиску ранжирующей функции, минимизирующей эмпирический функционал риска. 
В качестве её решения используется машина опорных векторов. 
Раздел 4 содержит основные понятия теории Демпстера-Шефера, позволяющей проводить неточные сравнения. 
В разделе 5 ставится формальная постановка задачи классификации в терминах неточных сравнений. 
Нижним и верхним границы функционала риска ставятся в соответствия нижние и верхние границы математического ожидания в рамках теории Демпстера-Шефера. 
Приводится описание минимаксной стратегии, используемой для вычисления функционала риска. 
Раздел 6 посвящён формулировке машины опорных векторов в терминах неточных сравнений.
При этом задача оптимизации сводится к двойственной и формулируется в терминах множителей Лагранжа. 
Приводится иллюстрационный пример построения задачи оптимизации. 


%======================================================================================================================

\section{Стандартная постановка задачи классификации}
\label{sec:standard_classification_problem}

\par
Для начала необходимо рассмотреть стандартную постановку задачи двоичной классификации.
Пусть дано множество, называемое обучающей выборкой:

\[
(\mathbf{x_1}, y_1),(\mathbf{x_2}, y_2), \dots, (\mathbf{x_n}, y_n) \in \mathbf{\chi} \times \{-1,+1\}
\]

\par
Здесь \(\mathbf{x_1}, \mathbf{x_2}, \dots, \mathbf{x_n}\) является непустым множеством образцов наблюдений или примеров, принимающих значения из множества \(\mathcal{X}\) и имеющие $l$ признаков (характеристик); \(y_1, \dots, y_n\) - классы, или выходные значения, которые могут принимать два значения: \emph{y} = -1 и \emph{y} = 1, соответствующие двум классам. 
Предполагается, что данные, приведённые выше, подчиняются неизвестной функции распределения \(F_0(\mathbf{x}, \emph{y})\) над множеством \(\mathbf{\chi} \times \{-1, +1\}\). 

\par
Целью классификации является нахождение решающей функции \(g(\mathbf{x})\), которая точно прогнозирует класс \emph{y}, которому принадлежит некоторый новый пример \(\mathbf{x}\), который в свою очередь может либо принадлежать, либо не принадлежать обучающей выборке. 
Другими словами, необходимо найти функцию \emph{g}, минимизирующую ошибку классификации, которая определяется вероятностью условия \(g(x) \neq y\). 
Один из возможных подходов для решения данной задачи является применение так называемой разделяющей функции \(f(\mathbf{x}, \mathbf{w})\). 
Эта вещественная функция, знак которой определяет класс: \(g(\mathbf{x})=sgn(f(\mathbf{x}, \mathbf{w}))\).
Она имеет параметры \(\mathbf{w}=(w_0, w_1, \dots, w_n), \mathbf{w} \in \Lambda, w = (w_1, \dots, w_n)\), которые опредляются на основе обучающей выборки посредством алгоритма классификации. 
В частности, функция \(f(\mathbf{x}, \mathbf{w})\) может быть линейной, то есть \(f(\mathbf{x}, \mathbf{w}) = \langle w, \mathbf{x} \rangle + w_0\). 
Обозначим \emph{i}-ый элемент вектора \(\mathbf{x_k}\) как \(x_i^{(k)}\). 

\par
Параметры \(\mathbf{w}\) могут быть найдены посредством минимизации функционала риска по множеству параметров функции \(f(\mathbf{x}, w), w \in \Lambda\):

\[
R(\mathbf{w}) = \int \limits_{\chi \times \{-1, +1\}} L(f, \mathbf{x}, y) \mathrm{d} F_0(\mathbf{x}, y).
\]

Здесь функция потерь \(L(f, \mathbf{x}, y)\) обычно принимает ненулевое значение, когда прогнозируемый при помощи разделяющей функции класс не совпадает с реальным классом \emph{y}, то есть имеет место ошибка классификации. 
В остальных случаях эта ошибка равна нулю. 

\par
Если имеется \emph{n} наблюдений, эмпирический функционал риска определяется путём предположения, что функция \(F_0(\mathbf{x}, y)\) оценивается во рамках аппарата непараметрических методов \reference{Wolfowitz1942} и имеет скачки размером 1/\emph{n} в точках \(x_1, \dots, x_n\). 
То есть эмпирический функционал риска определяется как

\[
R_{emp}(\mathbf{w}) = n^{-1} \cdot \sum \limits_{k=1}^n L(f_k, \mathbf{x}_k, y_k).
\]

Здесь \(f_k=f(\mathbf{x_k}, w)\). 

%======================================================================================================================

\section{Задача классификации на основе попарного обучения ранжированию}
\label{sec:pairwise_rank_learning_problem}

\par
Наиболее близким к концепции ранжирования является попарный подход, направленный не на точное предсказывание степени релевантности каждого документа, а на определение относительного порядка между парой документов. 
При использовании данного подхода ранжирование сводится к классификации пар документов, то есть к определению, какой из документов в паре является более предпочтительным.
Цель обучения в этом случае заключается в минимизации числа неправильно классифицированных пар документов. 
Таким образом, если все пары корректно классифицированы, то и сами документы, в свою очередь, корректно проранжированы. 

\par
В соответствии с данным подходом, сравниваются различные пары \((\mathbf{x},\mathbf{z})\) из множества \emph{M} объектов, где \(\mathbf{x}\) и \(\mathbf{z}\) - векторы с \emph{l} вещественнозначными признаками и принимают значения из множества \(\mathbf{\chi}\). 
Пусть \(\mathbf{x} \succ \mathbf{z}\) будет обозначать то, что \emph{i}-ый объект более предпочтителен, чем \emph{j}-ый, где \emph{i} и \emph{j} принадлежат множеству индексов \(\Rho\). 
Другими словами, обучающая выборка в попарном подходе состоит из пар объектов как обучающих экземпляров или примеров. 

\par
Для того чтобы рассматривать выходные значения, для начала необходимо определить две основные идеи попарного ранжирования, которые детально рассмотрены Лиу \reference{Liu2011}.
Первая из них - это анализ на основе U-статистики.
Она основывается на предположении, что объекты - статистически независимые случайные величины.
Вторая идея основана на анализе средних. 
Она предпологает, что пары объектов также являются статистически независимыми случайными величинами. 
Лиу приводит обоснование обоих идей. 
Ниже будет рассмотрена и использована только вторая. 
В то же время предлагаемый инструментарий может быть применён и к реализации первой идеи аналогичным образом. 

\par
В соответствии с идеей, предложенной Лиу \reference{Liu2011} и основывающейся на использовании математических ожиданий, каждая пара объектов \((\mathbf{x}, \mathbf{z})\) характеризуется выходной величиной \(y \in \{-1,1\}\), где \emph{y} = 1 означает, что данный объект с признаками \(\mathbf{x}\) является более предпочтительным, чем объект с признаками \(\mathbf{z}\), и \(\mathbf{x} \succ \mathbf{z}\). Если \(y = -1\), то в таком случае \(\mathbf{z} \succ \mathbf{x}\). Тогда предполагается, что \((\mathbf{x}, \mathbf{z}, y)\) является случайной величиной с функцией распределения \(F_1\). Функционал риска в данном случае определяется как

\[
R(\mathbf{w}) = \int \limits_{\chi \times \chi \times \{-1, 1\}} L(f, \mathbf{x}, \mathbf{z}, y) \mathrm{d} F_1(\mathbf{x}, \mathbf{z}, y)
\]

\par

Данный функционал риска означает ожидаемые потери, получающиеся в результате неправильной классификации случайных пар объектов некоторой разделяющей функцией \emph{f}. 

\par
Пусть имеется какое-то множество \emph{Q} из \emph{n} предпочтений, основывающихся на сравнительных оценках:

\[
Q = \{(\mathbf{x_1}, \mathbf{z_1}, y_1), (\mathbf{x_2}, \mathbf{z_2}, y_2), \dots, (\mathbf{x_n}, \mathbf{z_n}, y_n)\}
\]

\par
Задача классификации может быть сформулирована как вычисление ранжирующей функции \emph{f} из какого-то (параметрического) множества \emph{F}, такого, что \(f(\mathbf{x}, \mathbf{w}) \geq f(\mathbf{z}, \mathbf{w})\) при \(\mathbf{x} \succ \mathbf{z}\). 
Если предположить, что обучающая выборка не может одновременно содержать два элемента \((\mathbf{x}, \mathbf{z}, 1)\) и \((\mathbf{z}, \mathbf{x}, -1)\), то величина \emph{y} для краткости может быть опущена. 

\par
Обычный способ решения такой задачи классификации заключается в рассмотрении эмпирического функционала риска

\[
R_{emp}(\mathbf{w}) = \frac{1}{n} \sum \limits_{i=1}^n L(f_i, \mathbf{x_i}, \mathbf{z_i}).
\]

Теперь задача классификации может быть сформулирована как задача поиска оценочной, или ранжирующей, функции \(f(\mathbf{x}, \mathbf{w})\) (или её параметров \(\mathbf{w}\)), которая минимизирует эмпирический функционал риска, представленный выше. 

\par
Одним из наиболее известных подходов для поиска данной функции \emph{f} является применение модели RankSVM, которая проводит ранжирование путём минимизации регуляризируемого отступа на основе парных потерь. 
Модель RankSVM строится путём минимизации целевой функции \reference{Herbrich2000}, \reference{Joachims2002}

\[
\frac{1}{2} <w, w> + C \cdot \sum \limits_{i=1}^n L(f_i, \mathbf{x_i}, \mathbf{z_i}).
\] 

При этом функция потерь в RankSVM является петлевой функцией, определённой на паре объектов \(\mathbf{x} \succ \mathbf{z}\), то есть она имеет следующий вид:

\[
L(f, \mathbf{x}, \mathbf{z}, y) = max(0, 1 - (f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w}))).
\]

Если ввести переменные оптимизации \(\xi_i = max(0, 1 - (f(\mathbf{x_i}, \mathbf{w}) - f(\mathbf{z_i}, \mathbf{w}))\), то данная задача оптимизации может быть переписана в другом виде:

\[
\frac{1}{2}<w, w> + C \cdot \sum \limits_{i=1}^n \xi_i,
\]

при ограничениях

\[
f(\mathbf{x_i}, w) - f(\mathbf{z_i}, w) \geq 1 - \xi_i, 
\xi_i \geq 0, i = 1, \cdots, n.
\]

Если ранжирующая функция линейна, то исходная задача сводится к задаче квадратичного программирования.

%======================================================================================================================

\section{Основные элементы теории Демпстера-Шефера}
\label{sec:dst_definitions}

\par
Пусть \emph{U} - универсальное множество, обычно называемые \emph{фреймом различения} в теории свидетельств. 
Предположим, что было получено \emph{N} наблюдений элемента множества \(u \in U\).
При этом каждое наблюдение получено в результате неточного измерения, приводящего к множеству значений \emph{A}.
Обозначим \(c_i\) как количество появлений множества \(A_i \subseteq U\), а \(\Rho_o(U)\) множеством всех подмножеств \emph{U} (множество мощностей \emph{U}).
Частотная функция \emph{m}, называемая \emph{базовой вероятностью}, может быть определена как \reference{Dempster1967}, \reference{Shafer1976}:

\[
m : \Rho_o(U) \to [0,1],
m(\varnothing) = 1, \sum \limits_{A \in \Rho_o(U)} m(A) = 1.
\]

\par
Стоит отметить, что область определения базовой вероятности, \(\Rho_o(U)\), отличается от области определения функции плотности, которым является \emph{U}. 
В соответствии с \reference{Dempster1967}, эта функция может быть получена следующим образом:

\[
m(A_i) = c_i / N.
\]

\par
Если \(m(A_i) > 0\), то есть \(A_i\) встречается лишь один раз, то \(A_i\) называется \emph{фокальным элементом}. 

\par
В соответствии с \reference{Shafer1976}, оценки \emph{функции доверия} \(Bel(A)\) и \emph{функции правдоподобия} \(Pl(A)\) для какого-то события \(A \subseteq U\), могут быть определены как

\[
Bel(A) = \sum \limits_{A_i: A_i \subseteq A} m(A_i), 
Pl(A) = \sum \limits_{A_i: A_i \cap A \neq \varnothing} m(A_i).
\]

Как было указано в \reference{Halpern1992}, функция доверия может быть формально определена как функция, удовлетворяющая аксиомам, которые могут быть расценены как ослабление аксиом Колмогорова, характеризующие вероятностные функции. 
Поэтому разумно понимать функцию доверия как обобщённую вероятностную функцию \reference{Dempster1967}, а оценки функций доверия \(Bel(A)\) и правдоподобия \(Pl(A)\) могут рассматриваться как нижняя и верхняя границы для вероятности \emph{A}, то есть \(Bel(A) \leq Pr(A) \leq Pl(A)\).

\par
Если существует функция \(h(x)\), то её нижнее и верхнее математические ожидания в рамках теории функций доверия могут быть найдены следующим образом \reference{Nguyen1994}, \reference{Strat1990}:

\[
\mathbb{\overline{E}} h = \sum \limits_{i=1}^N m(A_i) \inf_{x \in A_i} h(x), 
\mathbb{\underline{E}} h = \sum \limits_{i=1}^N m(A_i) \sup_{x \in A_i} h(x).
\]

%======================================================================================================================

\section{Формальная постановка задачи классифкации в терминах неточных сравнений}
\label{sec:classification_problem_by_imprecise_comparisons}

\par
Предположим, что имеется \emph{M} объектов для сравнения \(\mathbf{\Psi} = \{\mathbf{x_1}, \mathbf{x_2}, \dots, \mathbf{x_M}\}\). 
Отсюда следует, что имеется \(N = M(M - 1)\) пар для сравнения. 
Эти \emph{N} пар \((\mathbf{x}, \mathbf{z})\) составляют фрейм различения \(\Omega\) в терминах теории Демпстера-Шефера. 
Предположим, что наши наблюдения или обучающая выборка состоит из \(b \leq N\) оценок вида \(\mathbf{A} \succ \mathbf{B}\), где \(\mathbf{A}\) и \(\mathbf{B}\) - некоторые дискретные множества объектов, таких что \(\mathbf{A} \cap \mathbf{B} = \varnothing\).  
Точные оценки \(\mathbf{x} \succ \mathbf{z}\) могут рассматриваться как частный случай неточных, когда множества \(\mathbf{A}\) и \(\mathbf{B}\) состоят из одного элемента. 
Другими словами, нельзя в общем смысле выделить простые или ``точные'' оценки сравнений вида \(\mathbf{x_i} \succ \mathbf{y_j}\), но зато, в свою очередь, имеются ``неточные'' оценки \(\mathbf{A} \succ \mathbf{B}\). 
Эти оценки означают отсутствие информации о том, как элементы из \(\mathbf{A}\) сравнимы между собой. 
То же самое может быть сказано и об элементах из \(\mathbf{B}\). 

\par
Перед дальнейшим рассмотрением этих неточных оценок определим их свойства:

\begin{enumerate}
\item Парное сравнение входит в другое парное сравнение, если каждое из элементов сравнений одной группы входит в элементы сравнения другой группы:

\begin{center}
\(\mathbf{C} \succ \mathbf{D} \subseteq \mathbf{A} \succ \mathbf{B}\), если \(\mathbf{C} \subseteq \mathbf{A}\) и \(\mathbf{D} \subseteq \mathbf{B}\).
\end{center}

\item Два сравнения не пересекаются между собой, если отдельные элементы этих сравнений не пересекаются:

\begin{center}
\(\mathbf{C} \succ \mathbf{D} \cap \mathbf{A} \succ \mathbf{B} = \varnothing\), если \(\forall\mathbf{x} \in \mathbf{C}\) и \(\forall\mathbf{y} \in \mathbf{D}\), то имеют место \(\mathbf{x} \notin \mathbf{A}\) и \(\mathbf{y} \notin \mathbf{B}\).
\end{center}

\end{enumerate}

\par 
Когда имеется \emph{m} точных оценок в форме \(\mathbf{x} \succ \mathbf{z}\), то эмпирический функционал риска может быть получен при предположении, что совместная функция распределения \(F(\mathbf{x}, \mathbf{y}, \mathbf{z})\) имеет скачки размером \emph{1/n} в точках \((\mathbf{x_1}, \mathbf{z_1}), (\mathbf{x_2}, \mathbf{z_2}), \dots, (\mathbf{x_n}, \mathbf{z_n})\). 
То есть она является непараметрической функцией распределения. 
Обозначим множество \emph{n} пар \((i, j)\) индексов, соответствующих оценкам \(\mathbf{A_i} \succ \mathbf{B_j}\) как \(\Rho\). 

\par
Введём базовые вероятности неточных оценок. 
Базовая вероятность оценки \(\mathbf{A_i} \succ \mathbf{B_j}\) определяется как \(m(\mathbf{A_i} \succ \mathbf{B_j}) = c_{ij} / n\), где \(c_{ij}\) - это количество оценок \(\mathbf{A_i} \succ \mathbf{B_j}\), пары индексов которых принадлежат множеству \(\Rho\). 
Далее для краткости предполагается, что \(c_{ij} = 1\) и \(m(\mathbf{A_i} \succ \mathbf{B_j}) = 1/n\) для всех наблюдаемых сравнений. 
Тогда можно записать нижние и верхние границы функционала риска как нижние и верхние границы математического ожидания в рамках теории Демпстера-Шефера:

\[
\underline{R}(\mathbf{w}) = \mathbb{\underline{E}}L = \sum \limits_{(i,j) \in \Rho} m(\mathbf{A_i} \succ \mathbf{B_j}) \cdot \underset{%
	\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}%
}{\operatorname{min}} %
L(f(\mathbf{x}, \mathbf{w})) - f(\mathbf{z}, \mathbf{w}))
\]

\[
= \frac{1}{n} \sum \limits_{(i,j) \in \Rho} \underset{%
\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}%
}{\operatorname{min}}%
L(f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})),
\]

\[
\overline{R}(\mathbf{w}) = \mathbb{\overline{E}} L = \sum \limits_{(i,j) \in \Rho} m(\mathbf{A_i} \succ \mathbf{B_j}) \cdot \underset{%
	\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}%
}{\operatorname{max}}
L (f (\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w}))
\]

\[
= \frac{1}{n} \sum \limits_{(i,j) \in \Rho} \underset{%
	\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}%
}{\operatorname{max}}%
L (f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})).
\]

\par
Стоит отметить, что неточная информация в виде неточных оценок сравнений образует множество вероятностных распределений. 
Каждое распределение из множества может быть использовано для вычисления функционала риска.
Однако неявно выбраны два вероятностных распределения, такие, что одно из распределений максимизирует оценку риска для каждого \(\mathbf{w}\), а второе распределение соответственно минизирует оценку риска. 
Выбор вероятностного распределения, максимизирующего оценку риска, может рассматриваться как минимаксная (пессимистичная) стратегия. 
Она может быть достаточно просто объяснена следующим образом. 
``Наихудшее'' распределение, обеспечивающее наибольшее значение функционала риска, должно быть выбрано из множества распределений. 
Критерий минимакса выступает в качестве страховки против наихудшего случая, так как он нацелен на минимизацию ожидаемой потери в наименее благоприятном случае \reference{Robert1994}. 
``Наилучшее'' распределение, обеспечивающее наименьшее значение функционала риска, приводит к миниминной (оптимистичной) стратегии.

%======================================================================================================================

\subsection{Минимаксная стратегия}

\par
Для начала рассмотрим верхнюю границу для оценки риска. 
Наша цель состоит в минимизации верхней оценки риска над множеством параметров \(\mathbf{w}\). 
Для этого введём новые переменные оптимизации \(G_{ij}, (i, j) \in \Rho\) такие, что

\[
G_{ij} = \underset{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}}{\operatorname{max}} L (f (\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})). 
\]

\par
Тогда задача оптимизации может быть переписана как

\[
\overline{R}(\mathbf{w}) = \underset{\mathbf{w}, G_{ij}}{\operatorname{min}} \sum \limits_{(i, j) \in \Rho} G_{ij},
\]

\par
при ограничениях

\[
G_{ij} \geq L (f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})), \forall \mathbf{x} \in \mathbf{A_i}, \forall \mathbf{z} \in \mathbf{B_j}, (i, j) \in \Rho
\]

\par
Здесь \(\mathbf{x}\) и \(\mathbf{z}\) могут быть взяты только из множества \(\Psi\). 

\par
Мы снова используем петлевую функцию потери, определённую на паре объектов \(\mathbf{x} \succ \mathbf{z}\)

\[
L(f, \mathbf{x}, \mathbf{z}) = max (0,1 - f(\mathbf{x}, \mathbf{w}) + f(\mathbf{z}, \mathbf{w})),
\]

\par
и линейную функцию \emph{f}. 
В этом случае можно переписать данную задачу оптимизации в следующем виде:

\[
\overline{R}(\mathbf{w}) = \underset{\mathbf{w}, G_{ij}}{\operatorname{min}} \sum \limits_{(i, j) \in \Rho} G_{ij},
\]

\par
при ограничениях

\[
G_{ij} + \langle w, \mathbf{x} - \mathbf{z} \rangle \geq 1, \forall \mathbf{x} \in \mathbf{A_i}, \forall \mathbf{z} \in \mathbf{B_j}, 
\]

\[
G_{ij} \succ 0, (i, j) \in \Rho.
\]

\par
Как результат, получена задача линейного программирования, соответствующая минимаксной стратегии. 
Можно увидеть, что данная задача оптимизации отличается от подобных задач, описанных другими авторами, например, \reference{Liu2011}, дополнительными ограничениями для каждой переменной \(G_{ij}\). 

%======================================================================================================================

\subsection{Миниминная стратегия}

\par
Существует также и другой ``крайний'' случай, когда рассматривается нижняя граница оценки риска. 
Производится поиск минимума минимумов, что приводит к задаче оптимизации с одним минимумом. 
Пусть переменные оптмимзации \(G_{ij}, (i, j) \in \Rho\) такие, что

\[
G_{ij} = \underset{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}}{\operatorname{min}} L (f (\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})). 
\]

\par
Это полностью совпадает с задачей оптимизации. При этом имеет место отсутствие ограничений, которые существуют в случае минимаксной стратегии.

\par
В отличие от минимаксной стратегии, миниминная не является устойчивой к ``помехам'', которые могут появляться по причине недостаточности обучающей выборки или присутствия в ней неточностей. 
Как следствие, большого практического значения она не имеет. 

%======================================================================================================================

\section{Формулировка машины опорных векторов при неточных сравнениях}
\label{sec:svm_by_imprecise_comparisons}

\par
Для того чтобы ограничить класс возможных решений задачи классификации и предотвратить переобучение, к целевой функции добавляется стабилизационное, или регуляризационное, слагаемое \(\Omega[f]\), в частности, \(\Omega[f] = \frac{1}{2}\|w\|^2 = \frac{1}{2} \langle w, w \rangle \). 
Это стандартное регуляризационное слагаемое, которое является наиболее популярным штрафом, или сглаживающим элементом, предложенным Тихоновым \reference{Tikhonov1977}. 
Сглаживающий элемент может рассматриваться как ограничение, которое обеспечивает уникальность с помощью функций штрафа со случайным колебанием и эффективно ограничивающее пространство допустимых решений. 
Более подробно анализ регуляризационных методов представлен в работах \reference{Evgeniou2002} \reference{Scholkopf2002}. 

\par
Тогда можно переписать целевую функцию следующим образом:

\[
\overline{R}(\mathbf{w}) = \frac{1}{2} \langle w, w \rangle + C \sum \limits_{(i, j) \in \Rho} G_{ij}. 
\]

\par
Здесь \emph{C} - это постоянный параметр ``стоимости'', который устанавливает компромисс между минимизацией функционала риска и гладкостью разделяющей функции \reference{Yu2009}. 
Таким образом, исходная задача сводится к задаче квадратичной оптимизации. 

\par
Вместо минимизации целевой функции прямой задачи оптимизации можно записать целевую функцию двойственной задачи, которая называется лагранжианом. 
Причём её седловая точка является оптимумом. 
Лагранжиан представлен в следующем виде:

\[
L = \frac{1}{2} \langle \mathbf{w}, \mathbf{w} \rangle + C \sum \limits_{(i, j) \in \Rho} G_{ij} - \sum \limits_{(i, j) \in \Rho} G_{ij} \eta_{ij}
\]

\[
- \sum \limits_{(i, j) \in \Rho, \mathbf{x} \in \mathbf{A_i}} \sum \limits_{\mathbf{z} \in \mathbf{B_j}} \mu_{ij}(\mathbf{x}, \mathbf{z}) (G_{ij} - 1 + \langle \mathbf{w}, \mathbf{x} - \mathbf{z} \rangle).
\]

\par
Здесь \(\eta_{ij}, \mu_{ij}(\mathbf{x}, \mathbf{z})\) являются множителями Лагранжа. 
Таким образом двойственные переменные должны удовлетворять ограничениям положительности \(\eta_{ij} \geq 0, \mu_{ij} (\mathbf{x}, \mathbf{z}) \geq 0\) для всех \((i, j) \in \Rho\) и соответствующих \(\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}\). 

\par
Седловая точка может быть найдена путём приравнивания производных нулю:

\[
\partial L / \partial w_k = w_k - \sum \limits_{(i, j) \in \Rho} \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z}) \cdot (\mathbf{x}^{(k)} - \mathbf{z}^{(k)}) = 0, k = 1, \dots, l,
\]

\[
\partial L / \partial G_{ij} = C - \eta_{ij} - \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \eta_{ij}(\mathbf{x}, \mathbf{z}) = 0, (i, j) \in \Rho. 
\]

\par
Здесь \(\mathbf{x}^{(k)}\) является \emph{k}-ым элементом вектора \(\mathbf{x}\). 
Путём подстановки \(\eta_{ij}\) из (5) в лагранжиан и дальнейшего упрощения получается:

\[
L = \frac{1}{2} \langle w, w \rangle - \sum \limits_{(i, j) \in \Rho} \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z}) \cdot (\langle w, \mathbf{x} - \mathbf{z} \rangle - 1).
\]

\par
После подстановки (4) в лагранжиан можно окончательно получить двойственную задачу оптимизации:
\mbox{}
\begin{eqnarray*}
&L = \sum \limits_{(i, j) \in \Rho} \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z}) - \\
&- \sum \limits_{(i, j) \in \Rho} \sum \limits_{(r, t) \in \Rho} \sum \limits_{\mathbf{x_1} \in \mathbf{A_i}, \mathbf{z_1} \in \mathbf{B_j}} \sum \limits_{\mathbf{x_2} \in \mathbf{A_r}, \mathbf{z_2} \in \mathbf{B_t}} \mu_{ij} (\mathbf{x_1}, \mathbf{z_1}) \cdot \mu_{rt} (\mathbf{x_2}, \mathbf{z_2}) \cdot \langle \mathbf{x_1} - \mathbf{z_1}, \mathbf{x_2} - \mathbf{z_2} \rangle
\end{eqnarray*}

\par
при ограничениях

\[
0 \leq \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z}) \leq C, (i, j) \in \Rho.
\]

\par
Условия Каруша-Куна-Такера являются следующими:
\mbox{}
\begin{eqnarray*}
&\mu_{ij}(\mathbf{x}, \mathbf{z}) \cdot (G_{ij} - 1 + \langle w, \mathbf{w} - \mathbf{z} \rangle) = 0,\\
&G_{ij} \cdot (C - \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z})) = 0.
\end{eqnarray*}

\par
Из задачи оптимизации можно увидеть, что она сведена к хорошо известной двойственной задаче квадратичной оптимизации (см. \reference{Yu2009}) в случае, когда \(\mathbf{A_i} = \{\mathbf{x_i}\}\) и \(\mathbf{B_i} = \{\mathbf{z_i}\}\)). 
Полученные результаты могут быть применены в пространстве признаков большей размерности, \(\varphi(\mathbf{x})\), для некоторой нелинейной функции \(\varphi\). 
Это достаточно просто получить путём замены скалярных произведений между преобразованными векторами признаков \((\varphi(\mathbf{x_1}) - \varphi(\mathbf{z_1})) (\varphi(\mathbf{x_2}) - \varphi(\mathbf{z_2}))\) при помощи ядра \(K(\mathbf{x_1}, \mathbf{z_1}, \mathbf{x_2}, \mathbf{z_2})\), где (см. \reference{Herbrich2000})

\[
K(\mathbf{x_1}, \mathbf{z_1}, \mathbf{x_2}, \mathbf{z_2}) = K(\mathbf{x_1}, \mathbf{x_2}) - K(\mathbf{x_1}, \mathbf{z_2}) - K(\mathbf{z_1}, \mathbf{x_2}) + K(\mathbf{z_1}, \mathbf{z_2}).
\]

\par
Здесь \(K(\mathbf{x_1}, \mathbf{z_1}, \mathbf{x_2}, \mathbf{z_2})\) является ядром Мерсера. 
Таким образом задача оптимизации сводится к следующему виду:
\mbox{}
\begin{eqnarray*}
&L = \sum \limits_{(i, j) \in \Rho} \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z}) - \\
&- \sum \limits_{(i, j) \in \Rho} \sum \limits_{(r, t) \in \Rho} \sum \limits_{\mathbf{x_1} \in \mathbf{A_i}, \mathbf{z_1} \in \mathbf{B_j}} \sum \limits_{\mathbf{x_2} \in \mathbf{A_r}, \mathbf{z_2} \in \mathbf{B_t}} \mu_{ij} (\mathbf{x_1}, \mathbf{z_1}) \cdot \mu_{rt} (\mathbf{x_2}, \mathbf{z_2}) \cdot K(\mathbf{x_1}, \mathbf{z_1}, \mathbf{x_2}, \mathbf{z_2}).
\end{eqnarray*}

%======================================================================================================================

\subsection{Пример построения задачи оптимизации}

\par
В качестве примера возьмём ситуацию, которая нередко случается в обычной жизни.
Перед поездкой в другой город семья, как правило, заранее планирует, какие исторические места в нём она собирается посетить. 
Пусть в городе \textit{N} ими являются исторический центр, набережная и дворцово-парковый комплекс. 
Рядом с каждым из них находится большое количество достопримечательностей. 
В связи с ограниченностью во времени родители предлагают посетить набережную и исторический центр, так как в отличие от дворцового-паркового комплекса они находятся недалеко друг от друга. 
Но дети говорят о том, что вместо исторического центра они бы хотели посетить именно дворец. 
Какие достопримечательности стоит посетить, чтобы учесть пожелания членов семьи?

\par
В нашем случае имеется 3 объекта (исторические места) и 2 сравнительные оценки (пожелания членов семьи), одна из которых является интервальной. 
Целью данного примера является иллюстрация поиска целевой функции, с помощью которой можно ответить на поставленный вопрос. 

\par
Пусть исторический центр будет обозначаться как \(x_1\), набережная как \(x_2\), а дворцово-парковый комплекс как \(x_3\). 
Соответственно, предпочтения будут выглядеть следующим образом: 
\[
\{x_1, x_2\} \succ \{x_3\}; \{x_3\} \succ \{x_1\}.
\]

\par
Тогда множества \(\mathbf{A}\) и \(\mathbf{B}\) будут обозначены так:

\[
A_1 = \{x_1, x_2\}, A_2 = \{x_3\}; B_1 = \{x_3\}, B_2 = \{x_1\}.
\]

\par
Для краткости разделим формулу целевой функции на две части:
\mbox{}
\begin{eqnarray*}
& L = L_1 - L_2;\\ \\
& L_1 = \mu_{11}(A_1, B_1) + \mu_{12}(A_1, B_2) + \mu_{21}(A_2, B_1) + \mu_{22}(A_2, B_2);\\ \\
&L_2 = K(A_1, A_1, B_1, B_1) \cdot \mu^{2}_{11}(A_1, B_1)
+ K(A_1, A_1, B_1, B_2) \cdot \mu_{11}(A_1, B_1) \cdot \mu_{12}(A_1, B_2) +\\
&+ K(A_1, A_1, B_2, B_1) \cdot \mu_{11}(A_1, B_1) \cdot \mu_{12}(A_1, B_2)
+ K(A_1, A_1, B_2, B_2) \cdot \mu^{2}_{12}(A_1, B_2) +\\
&+ K(A_1, A_2, B_1, B_1) \cdot \mu_{11}(A_1, B_1) \cdot \mu_{21}(A_2, B_1)
+ K(A_2, A_1, B_1, B_1) \cdot \mu_{11}(A_1, B_1) \cdot \mu_{21}(A_2, B_1) +\\
&+ K(A_1, A_2, B_2, B_1) \cdot \mu_{12}(A_1, B_2) \cdot \mu_{21}(A_2, B_1)
+ K(A_2, A_1, B_1, B_2) \cdot \mu_{12}(A_1, B_2) \cdot \mu_{21}(A_2, B_1) +\\
&+ K(A_2, A_2, B_1, B_1) \cdot \mu^{2}_{21}(A_2, B_1)+
+ K(A_1, A_2, B_1, B_2) \cdot \mu_{11}(A_1, B_1) \cdot \mu_{22}(A_2, B_2)+\\
&+ K(A_2, A_1, B_2, B_1) \cdot \mu_{11}(A_1, B_1) \cdot \mu_{22}(A_2, B_2)
+ K(A_1, A_2, B_2, B_2) \cdot \mu_{12}(A_1, B_2) \cdot \mu_{22}(A_2, B_2) +\\
&+ K(A_2, A_1, B_2, B_2) \cdot \mu_{12}(A_1, B_2) \cdot \mu_{22}(A_2, B_2)
+ K(A_2, A_2, B_1, B_2) \cdot \mu_{21}(A_2, B_1) \cdot \mu_{22}(A_2, B_2) +\\
&+ K(A_2, A_2, B_2, B_1) \cdot \mu_{21}(A_2, B_1) \cdot \mu_{22}(A_2, B_2)
+ K(A_2, A_2, B_2, B_2) \cdot \mu^{2}_{22}(A_2, B_2).
\end{eqnarray*}

\par
В итоге целевая функция будет выглядеть так:
\mbox{}
\begin{eqnarray*}
&L = \mu_{11}(x_1, x_3) + \mu_{11}(x_2, x_3) + \mu_{21}(x_2, x_1) + \mu_{22}(x_3, x_1) - \\
&- (K(x_1, x_1) - K(x_1, x_3) + K(x_2, x_1) - K(x_2, x_3) - K(x_3, x_1) + K(x_3, x_ 3)) \cdot \\
&\cdot (\mu_{11}(x_1, x_3) + \mu_{11}(x_3, x_3))^{2} + \mu_{12}(x_1, x_1) + \mu_{12}(x_2, x_1) - \\
&- (K(x_2, x_1) - K(x_2, x_3)) \cdot (\mu_{11}(x_1, x_3) + \mu_{11}(x_2, x_3)) \cdot (\mu_{12}(x_1, x_1) + \mu_{12}(x_2, x_1)) +\\
&- (-K(x_1, x_1) + K(x_1, x_3) + K(x_3, x_1) - K(x_3, x_2)) \cdot \\
&\cdot (\mu_{11}(x_1, x_3) + \mu_{11}(x_2, x_3)) \cdot \mu_{22}(x_3, x_1) - \\
&- (-K(x_1, x_1) + K(x_1, x_3) - K(x_2, x_1) + K(x_2, x_3) + K(x_3, x_1) - K(x_3, x_3)) \cdot \\
& \cdot (\mu_{11}(x_1, x_3) + \mu_{11}(x_2, x_3)) \cdot \mu_{22}(x_3, x_1) -\\
&- (-K(x_2, x_1) + K(x_2, x_3)) \cdot \cdot (\mu_{12}(x_1, x_1) + \mu_{12}(x_2, x_1)) \cdot \mu_{22}(x_3, x_1) - \\
&- (K(x_1, x_1) - K(x_1, x_3) - K(x_3, x_1) + K(x_3, x_3)) \cdot \mu^{2}_{22}(x_3, x_1)
\end{eqnarray*}

\par
при следующих ограничениях
\mbox{}
\begin{eqnarray*}
0 \leq \mu_{11}(x_1, x_3) + \mu_{11}(x_2, x_3) + \mu_{12}(x_1, x_1) + \mu_{12}(x_2, x_1) + \mu_{21}(x_3, x_3) + \mu_{21}(x_3, x_1) \leq C,
\end{eqnarray*}

\par
где \(C\) - параметр стоимости. 

\par
При этом стотит отметить, что ядро \(K(\mathbf{x},\mathbf{y})\) может быть любым. 
Чаще всего используется Гауссово ядро с параметром \(\gamma\), которое может быть вычислено по следующей формуле:
\mbox{}
\begin{eqnarray*}
&K(\mathbf{x}, \mathbf{y}) = e^{-\frac{||\mathbf{x}-\mathbf{y}||^2}{\gamma^{2}}}.
\end{eqnarray*}

%======================================================================================================================
\section{Заключение}
\label{sec:conclusions}

\par
В статье предлагается новый подход к классификации документов на основе групповых экспертных оценок.
Данный подход характеризуется использованием машины опорных векторов в качестве средства обучения и пессимистической стратегией принятия решений. 
Для анализа экспертных оценок, являющихся интервальными, предложен аппарат теории свидетельств Демпстера-Шефера. 
\par
В результате применения данного подхода разработана соответствующая задача оптимизации в виде обобщения машины опорных векторов, направленного на поддержку интервального характера экспертных оценок. 
Получена двойственная форма данной задачи, которая представлена в терминах множителя Лагранжа и позволяет использовать нелинейность для построения более адекватной модели. 
Приведён пример, иллюстрирующий алгоритм построения данной оптимизационной задачи. 
\par
Предложенный в статье подход был реализован для случая попарной классификации, но он так же может быть реализован и для случаев поточечной и посписочной классификации в рамках дальнейшей работы. 
Вместе с этим небольшой иллюстрационный пример, приведённый в статье, показывает сложность задачи с вычислительной точки зрения, что говорит о необходимости дальнейшего исследования, направленного на попытку сокращения объёма вычислений и уменьшения сложности данной задачи. 

%======================================================================================================================

\begin{thebibliography}{9}
	%1
	\bibitem{Herbrich2000} R. Herbrich, T. Graepel, K. Obermayer. Large margin rank boundaries for ordinal regression. Smola, Bartlett, Schoelkopf, and Schuurmans, editors, Advances in Large Margin Classifiers, pp. 115–132. MIT Press, Cambridge, MA, 2000%
	\bibitem{Wolfowitz1942} J. Wolfowitz. Additive partition functions and a class of statistical hypotheses. Annals of Mathematical Statistics, 13(3), pp. 247–279, 1942%
	\bibitem{Liu2011} T.Y. Liu. Learning to Rank for Information Retrieval, Springer, 2011%
	\bibitem{Joachims2002} T. Joachims. Optimizing search engines using clickthrough data. Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2002), pp. 133–142, 2002%
	\bibitem{Dempster1967} A.P. Dempster. Upper and lower probabilities induced by a multi-valued mapping. Annales of Mathematical Statistics, 38(2), pp. 325–339, 1967%
	\bibitem{Shafer1976} G. Shafer. A Mathematical Theory of Evidence. Princeton University Press, 1976%
	\bibitem{Halpern1992} J.Y. Halpern, R. Fagin. Two views of belief: Belief as generalized probability and belief as evidence. Artificial Intelligence, 54(3), pp. 275–317, 1992%
	\bibitem{Nguyen1994} H.T. Nguyen,  E.A. Walker. On decision making using belief functions. In R.Y. Yager, M. Fedrizzi, and J. Kacprzyk, editors, Advances in the Dempster-Shafer theory of evidence, pp. 311–330. Wiley, New York, 1994%
	\bibitem{Strat1990} T.M. Strat. Decision analysis using belief functions. International Journal of Approximate Reasoning, 4(5), pp. 391–418, 1990%
	\bibitem{Robert1994} C.P. Robert. The Bayesian Choice. Springer, New York, 1994%
	\bibitem{Tikhonov1977} A.N. Tikhonov, V.Y. Arsenin. Solution of Ill-Posed Problems. W.H. Winston, Washington DC, 1977%
	\bibitem{Evgeniou2002} T. Evgeniou, T. Poggio, M. Pontil, A. Verri. Regularization and statistical learning theory for data analysis. Computational Statistics \& Data Analysis, 38(4), pp. 421–432, 2002%
	\bibitem{Scholkopf2002} B. Scholkopf, A.J. Smola. Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond. The MIT Press, Cambridge, Massachusetts, 2002%
	\bibitem{Yu2009} H. Yu, Y. Kim, S. Hwang. Rv-svm: An efficient method for learning ranking SVM. T. Theeramunkong, B. Kijsirikul, N. Cercone, and T.-B. Ho, editors, Advances in Knowledge Discovery and Data Mining, vol. 5476 of Lecture Notes in Computer Science, pp. 426–438. Springer Berlin / Heidelberg, 2009%
\end{thebibliography}

\end{document}
