% sudo apt-get install texlive-latex-base
% sudo apt-get install texlive-fonts-extra
% sudo apt-get install texlive-latex-recommended
% sudo apt-get install texlive-lang-cyrillic

\documentclass[12pt,a4paper,oneside]{article}

\title{Нечёткий метод опорных векторов}
\author{Л.В. Уткин}
\date{\today}

\usepackage[utf8]{inputenc} % возможность использования Unicode-символов в исходных файлах

\usepackage{amsmath} % для поддержки расширенных математических символов
\usepackage{amsfonts} % для поддержки математических шрифтов
\usepackage{amssymb} % для поддержки расширенных математических символов
\usepackage{color} % для поддержки цвета текста, отличного от чёрного
\usepackage{datetime} % поддержка календаря и дат
\usepackage{fancyhdr} % использование собственного формата заголовков
\usepackage[T2A]{fontenc} % задание шрифта
\usepackage{geometry} % задания страничных отступов
\usepackage{graphicx} % поддержка PNG-формата в качестве иллюстраций
\usepackage[pdftex,bookmarks,unicode]{hyperref} % поддержка возможности использования ссылок в качестве гиперссылок
\usepackage{indentfirst} % отступ первого параграфа в разделе
\usepackage{setspace} % задание межстрочного интервала
\usepackage{verbatim} % скрытие "comment-окружений" из результирующего документа
\usepackage[english,russian]{babel} % поддержка переносов слов

\hypersetup{
%	bookmarkstype=none,
%	plainpages=false,
	pdftitle={Нечёткий SVM},
	pdfauthor={И.Ю. Ботян, Л.В. Уткин},
	pdfsubject={Статья},
	pdfnewwindow=false,
	pdfkeywords={машина опорных векторов, ранжирование документов, задача классификации},
	colorlinks=true,
	linkcolor=black,
	citecolor=black,
	filecolor=black,
	urlcolor=black,
	pageanchor=false} % если пакет "lastpage" импортирован, то необходимо отключить данную опцию

% задание страничных отступов
\geometry{left=2.5cm}
\geometry{right=2.0cm}
\geometry{top=2.0cm}
\geometry{bottom=2.5cm}

\onehalfspacing % задание полуторного межстрочного интервала
\setlength{\parindent}{25pt} % задание абзацного отступа в 5 символов
\setlength{\headheight}{28pt}

\begin{document}

\input{tex_definitions}
\ApplyCommonPageStyle

%======================================================================================================================

\section{Введение}
\label{sec:introduction}

\par
В порядковой регрессии рассматривается задача, которая имеет свойства, присущие как классификации в целом (i), так и метрической регрессии (ii). 
Как в (i) класс $y$ является конечным множеством, так и в (ii) присутствует упорядочение среди элементов $y$ \reference{Herbrich2000}.

\par
Например, класс \emph{0} может соответствовать понятию ``нерелевантности'', а класс \emph{y\sub{max}}, в свою очередь, может соответствовать понятию ``наибольшей релевантности''. 
Часто данные классы явно определяются так называемыми \emph{экспертами}. 
Тогда как, например, в случае веб-документов они задаются посредством анализа переходов по ссылкам между ними (\emph{clickthrough data}). 

\par
Данные классы используются в задачах классификации, в которой каждый элемент заданного множества документов соотносится с тем или иным классом. 
При этом если между самими классами задан некоторый порядок, то имеет место задача ранжирования документов. 

\par
Наиболее близким к концепции ранжирования является попарный подход, направленный не на точное предсказывание степени релевантности каждого документа, а на определение относительного порядка между парой документов. 
При использовании данного подхода ранжирование обычно сводится к классификации пар документов, то есть к определению, какой из документов в паре является более предпочтительным.
Цель обучения в этом случае заключается в минимизации числа неправильно классифицированных пар документов. 
Таким образом, если все пары корректно классифицированы, то и сами документы, в свою очередь, корректно проранжированы. 

\par
В настоящее время существует большое количество моделей обучения ранжированию, основанных на попарном подходе. 
Среди них одной из наиболее популярных и в то же время эффективных является машина опорных векторов \reference{Herbrich2000} \reference{Joachims2002}. 
Её основной особенностью является возможность применения нелинейных разделяющих функций при помощи так называемых ядер. 
Машина опорных векторов относится к алгоритмам обучения с учителем. 

\par
Наряду с машиной опорных векторов существуют и другие модели ранжирования. 
Одним из них является искусственная нейронная сеть \reference{Burges2005}.  
С математической точки зрения, обучение нейронных сетей представляет собой многопараметрическую задачу нелинейной оптимизации. 
Ранжирование также может быть также проведено при помощи перцептрона \reference{Gao2005} \reference{Shen2005}, одним из основных свойств которого является способность к обучению как с учителем, так и без него. 
В свою очередь, может использоваться и процедура бустинга \reference{Freund2003}, которая заключается в последовательном построении композиции алгоритмов машинного обучения. 
При этом каждый следующий алгоритм в этом случае стремится компенсировать недостатки композиции всех предыдущих алгоритмов. 
Помимо моделей ранжирования, перечисленных выше, существуют и многие другие \reference{Cohen1998} \reference{Tsai2007} \reference{Zheng2007} \reference{Zheng2008}. 

% эта проблема является предпосылкой для нашего исследования?

\par
С процессом ранжироrвания связана проблема, имеющая место в случае, если пары документов не являются статистически независимыми, так как это приводит к нарушению основного предположения, лежащего в алгоритмах классификации. 
При этом хотя в некоторых случаях предположение действительно не может быть верным, это всё-таки не мешает использованию средств классификации для обучения модели ранжирования. 
Однако принципиально иная теоретическая база необходима для анализа обобщения процесса обучения. 

% какая проблема у нас в статье? что является предпосылкой для её написания?

\par
В статье предлагается новый подход к классификации документов на основе групповых экспертных оценок.
Он заключается в применении машины опорных векторов с использованием теории свидетельств Демпстера-Шефера и характеризуется пессимистической стратегией принятия решений. 
В результате применения данного подхода формулируется соответствующая задача квадратичного программирования конечной размерности. 
Основной целью статьи является реализация данной задачи, позволяющей проводить классификацию документов в условиях, описанных выше. 

% можно упомянуть про проведение эксперимента

%======================================================================================================================

\section{Стандартная постановка задачи классификации}
\label{sec:standard_classification_problem}

\par
Для начала необходимо рассмотреть стандартную постановку задачи двоичной классификации.
Пусть дано множество, называемое обучающей выборкой:

\[
(\mathbf{x_1}, y_1),(\mathbf{x_2}, y_2), \dots, (\mathbf{x_n}, y_n) \in \mathbf{\chi} \times \{-1,+1\}
\]

\par
Здесь \(\mathbf{x_1}, \mathbf{x_2}, \dots, \mathbf{x_n}\) является непустым множеством образцов наблюдений или примеров, принимающих значения из множества \(\mathcal{X}\) и имеющие $l$ признаков (характеристик); \(y_1, \dots, y_n\) - классы, или выходные значения, которые могут принимать два значения: \emph{y} = -1 и \emph{y} = 1, соответствующие двум классам. 
Предполагается, что данные, приведённые выше, подчиняются неизвестной функции распределения \(F_0(\mathbf{x}, \emph{y})\) над множеством \(\mathbf{\chi} \times \{-1, +1\}\). 

\par
Целью классификации является нахождение решающей функции \(g(\mathbf{x})\), которая точно прогнозирует класс \emph{y}, которому принадлежит некоторый новый пример \(\mathbf{x}\), который в свою очередь может либо принадлежать, либо не принадлежать обучающей выборке. 
Другими словами, необходимо найти функцию \emph{g}, минимизирующую ошибку классификации, которая определяется вероятностью условия \(g(x) \neq y\). 
Один из возможных подходов для решения данной задачи является применение так называемой разделяющей функции \(f(\bolsymbol{x}, \mathbf{w})\). 
Эта вещественная функция, знак которой определяет класс: \(g(\mathbf{x})=sgn(f(\mathbf{x}, \mathbf{w}))\).
Она имеет параметры \(\mathbf{w}=(w_0, w_1, \dots, w_n), \mathbf{w} \in \Lambda, w = (w_1, \dots, w_n)\), которые опредляются на основе обучающей выборки посредством алгоритма классификации. 
В частности, функция \(f(\mathbf{x}, \mathbf{w})\) может быть линейной, то есть \(f(\mathbf{x}, \mathbf{w}) = \langle w, \mathbf{x} \rangle + w_0\). 
Обозначим \emph{i}-ый элемент вектора \(\mathbf{x_k}\) как \(x_i^{(k)}\). 

\par
Параметры \(\mathbf{w}\) могут быть найдены посредством минимизации функционала риска по множеству параметров функции \(f(\mathbf{x}, w), w \in \Lambda\):

\[
R(\mathbf{w}) = \int \limits_{\chi \times \{-1, +1\}} L(f, \mathbf{x}, y) \mathrm{d} F_0(\mathbf{x}, y).
\]

Здесь функция потерь \(L(f, \mathbf{x}, y)\) обычно принимает ненулевое значение, когда прогнозируемый при помощи разделяющей функции класс не совпадает с реальным классом \emph{y}, то есть имеет место ошибка классификации. 
В остальных случаях эта ошибка равна нулю. 

\par
Если имеется \emph{n} наблюдений, эмпирический функционал риска определяется путём предположения, что функция \(F_0(\mathbf{x}, y)\) оценивается во рамках аппарата непараметрических методов \reference{Wolfowitz1942} и имеет скачки размером 1/\emph{n} в точках \(x_1, \dots, x_n\). 
То есть эмпирический функционал риска определяется как

\[
R_{emp}(\mathbf{w}) = n^{-1} \cdot \sum \limits_{k=1}^n L(f_k, \mathbf{x}_k, y_k).
\]

Здесь \(f_k=f(\mathbf{x_k}, w)\). 

%======================================================================================================================

\section{Задача классификации на основе попарного обучения ранжированию}
\label{sec:pairwise_rank_learning_problem}

\par
Так как основной целью является определение, какой объект в паре является более предпочтительным, то проблема классификации сводится к классификации пар объектов. 
В этом случае можно говорить о попарном подходе. 
В соответствии с данным подходом к решению задачи классификации, сравниваются различные пары \((\mathbf{x},\mathbf{z})\) из множества \emph{M} объектов. 
Здесь \(\mathbf{x}\) и \(\mathbf{z}\) - векторы с \emph{l} вещественнозначными признаками и принимают значения из множества \(\mathbf{\chi}\). 
Мы будем обозначать \(\mathbf{x} \succ \mathbf{z}\), предполагая, что \emph{i}-ый объект более предпочтителен, чем \emph{j}-ый. 
Другими словами, обучающая выборка в попарном подходе состоит из пар объектов как обучающие экземпляры или примеры. 

\par
Для того чтобы рассматривать выходные значения, для начала необходимо определить две основные идеи попарного ранжирования, которые детально рассмотрены Лиу \reference{Liu2011}.
Первая из них - это анализ на основе U-статистики.
Она основывается на предположении, что объекты - статистически независимые случайные величины.
Вторая идея основана на анализе средних. 
Она предпологает, что пары объектов также являются статистически независимыми случайными величинами. 
Лиу приводит обоснование обоих идей. 
Ниже будет рассмотрена и использована только вторая. 
В то же время предлагаемый инструментарий может быть применён и к реализации первой идеи аналогичным образом. 

\par
В соответствии с идеей, предложенной Лиу \reference{Liu2011} и основывающейся на использовании математических ожиданий, каждая пара объектов \((\mathbf{x}, \mathbf{z})\) характеризуется выходной величиной \(y \in \{-1,1\}\), где \emph{y} = 1 означает, что данный объект с признаками \(\mathbf{x}\) является более предпочтительным, чем объект с признаками \(\mathbf{z}\), и \(\mathbf{x} \succ \mathbf{z}\). Если \(y = -1\), то в таком случае \(\mathbf{z} \succ \mathbf{x}\). Тогда предполагается, что \((\mathbf{x}, \mathbf{z}, y)\) является случайной величиной с функцией распределения \(F_1\). Функционал риска в данном случае определяется как

\[
R(\mathbf{w}) = \int \limits_{\chi \times \chi \times \{-1, 1\}} L(f, \mathbf{x}, \mathbf{z}, y) \mathrm{d} F_1(\mathbf{x}, \mathbf{z}, y)
\]

\par

Данный функционал риска означает ожидаемые потери, получающиеся в результате неправильной классификации случайных пар объектов некоторой разделяющей функцией \emph{f}. 

\par
Пусть имеется какое-то множество \emph{Q} из \emph{n} предпочтений, основывающихся на сравнительных оценках:

\[
Q = \{(\mathbf{x_1}, \mathbf{z_1}, y_1), \mathbf{x_2}, \mathbf{z_2}, y_2), \dots, \mathbf{x_n}, \mathbf{z_n}, y_n)\}
\]

\par
Задача классификации может быть сформулирована как вычисление ранжирующей функции \emph{f} из какого-то (параметрического) множества \emph{F}, такого, что \(f(\mathbf{x}, \mathbf{w}) \geq f(\mathbf{z}, \mathbf{w})\) при \(\mathbf{x} \succ \mathbf{z}\). 
Если предположить, что обучающая выборка не может одновременно содержать два элемента \((\mathbf{x}, \mathbf{z}, 1)\) и \((\mathbf{z}, \mathbf{x}, -1)\), то величина \emph{y} для краткости может быть опущена. 

\par
Обычный способ решения такой задачи классификации заключается в рассмотрении эмпирического функционала риска

\[
R_{emp}(\mathbf{w}) = \frac{1}{n} \sum \limits_{i=1}^n L(f_i, \mathbf{x_i}, \mathbf{z_i}).
\]

Теперь задача классификации может быть сформулирована как задача поиска оценочной, или ранжирующей, функции \(f(\mathbf{x}, \mathbf{w})\) (или её параметров \(\mathbf{w}\)), которая минимизирует эмпирический функционал риска, представленный выше. 

\par
Одним из наиболее известных подходов для поиска данной функции \emph{f} является применение модели RankSVM, которая проводит ранжирование путём минимизации регуляризируемого отступа на основе парных потерь. 
Модель RankSVM строится путём минимизации целевой функции \reference{Herbrich2000}, \reference{Joachims2002}

\[
\frac{1}{2} <w, w> + C \cdot \sum \limits_{i=1}^n L(f_i, \mathbf{x_i}, \mathbf{z_i}).
\] 

При этом функция потерь в RankSVM является петлевой функцией, определённой на паре объектов \(\mathbf{x} \succ \mathbf{z}\), то есть она имеет следующий вид:

\[
L(f, \mathbf{x}, \mathbf{z}, y) = max(0, 1 - (f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w}))).
\]

Если ввести переменные оптимизации \(\xi_i = max(0, 1 - (f(\mathbf{x_i}, \mathbf{w}) - f(\mathbf{z_i}, \mathbf{w}))\), то данная задача оптимизации может быть переписана в другом виде:

\[
\frac{1}{2}<w, w> + C \cdot \sum \limits_{i=1}^n \xi_i,
\]

при ограничениях

\[
f(\mathbf{x_i}, w) - f(\mathbf{z_i}, w) \geq 1 - \xi_i, 
\xi_i \geq 0, i = 1, \cdots, n.
\]

Если ранжирующая функция линейна, то исходная задача сводится к задаче квадратичного программирования.

%======================================================================================================================

\section{Основные элементы теории Демпстера-Шефера}
\label{sec:dst_definitions}

\par
Пусть \emph{U} - универсальное множество, обычно называемые \emph{фреймом различения} в теории свидетельств. 
Предположим, что было получено \emph{N} наблюдений элемента множества \(u \in U\).
При этом каждое наблюдение получено в результате неточного измерения, приводящего к множеству значений \emph{A}.
Обозначим \(c_i\) как количество появлений множества \(A_i \subseteq U\), а \(\Rho_o(U)\) множеством всех подмножеств \emph{U} (множество мощностей \emph{U}).
Частотная функция \emph{m}, называемая \emph{базовой вероятностью}, может быть определена как \reference{Dempster1967}, \reference{Shafer1976}:

\[
m : \Rho_o(U) \to [0,1],
m(\varnothing) = 1, \sum \limits_{A \in \Rho_o(U)} m(A) = 1.
\]

\par
Стоит отметить, что область определения базовой вероятности, \(\Rho_o(U)\), отличается от области определения функции плотности, которым является \emph{U}. 
В соответствии с \reference{Dempster1967}, эта функция может быть получена следующим образом:

\[
m(A_i) = c_i / N.
\]

\par
Если \(m(A_i) > 0\), то есть \(A_i\) встречается лишь один раз, то \(A_i\) называется \emph{фокальным элементом}. 

\par
В соответствии с \reference{Shafer1976}, оценки \emph{функции доверия} \(Bel(A)\) и \emph{функции правдоподобия} \(Pl(A)\) для какого-то события \(A \subseteq U\), могут быть определены как

\[
Bel(A) = \sum \limits_{A_i: A_i \subseteq A} m(A_i), 
Pl(A) = \sum \limits_{A_i: A_i \cap A \neq \varnothing} m(A_i).
\]

Как было указано в \reference{Halpern1992}, функция доверия может быть формально определена как функция, удовлетворяющая аксиомам, которые могут быть расценены как ослабление аксиом Колмогорова, характеризующие вероятностные функции. 
Поэтому разумно понимать функцию доверия как обобщённую вероятностную функцию \reference{Dempster1967}, а оценки функций доверия \(Bel(A)\) и правдоподобия \(Pl(A)\) могут рассматриваться как нижняя и верхняя границы для вероятности \emph{A}, то есть \(Bel(A) \leq Pr(A) \leq Pl(A)\).

\par
Если существует функция \(h(x)\), то её нижнее и верхнее математические ожидания в рамках теории функций доверия могут быть найдены следующим образом \reference{Nguyen1994}, \reference{Strat1990}:

\[
\mathbb{\overline{E}} h = \sum \limits_{i=1}^N m(A_i) \inf_{x \in A_i} h(x), 
\mathbb{\underline{E}} h = \sum \limits_{i=1}^N m(A_i) \sup_{x \in A_i} h(x).
\]

%======================================================================================================================

\section{Формальная постановка задачи классифкации в терминах неточных сравнений}
\label{sec:classification_problem_by_imprecise_comparisons}

\par
Предположим, что имеется \emph{M} объектов для сравнения \(\mathbf{\Psi} = \{\mathbf{x_1}, \mathbf{x_2}, \dots, \mathbf{x_M}\}\). 
Отсюда следует, что имеется \(N = M(M - 1)\) пар для сравнения. 
Эти \emph{N} пар \((\mathbf{x}, \mathbf{z})\) составляют фрейм различения \(\Omega\) в терминах теории Демпстера-Шефера. 
Предположим, что наши наблюдения или обучающая выборка состоит из \(b \leq N\) оценок вида \(\mathbf{A} \succ \mathbf{B}\), где \(\mathbf{A}\) и \(\mathbf{B}\) - некоторые множества объектов, таких что \(\mathbf{A} \cap \mathbf{B} = \varnothing\).  
Точные оценки \(\mathbf{x} \succ \mathbf{z}\) могут рассматриваться как частный случай неточных, когда множества \(\mathbf{A}\) и \(\mathbf{B}\) состоят из одного элемента. 
Другими словами, нельзя в общем смысле выделить простые или ``точные'' оценки сравнений вида \(\mathbf{x_i} \succ \mathbf{y_j}\), но зато, в свою очередь, имеютя ``неточные'' оценки \(\mathbf{A} \succ \mathbf{B}\). 
Эти оценки означают отсутствие информации о том, как элементы из \(\mathbf{A}\) сравнимы между собой. 
То же самое может быть сказано и об элементах из \(\mathbf{B}\). 

\par
Перед дальнейшим рассмотрением этих неточных оценок определим их свойства:

\begin{enumerate}
\item Парное сравнение входит в другое парное сравнение, если каждое из элементов сравнений одной группы входит в элементы сравнения другой группы:

\begin{center}
\(\mathbf{C} \succ \mathbf{D} \subseteq \mathbf{A} \succ \mathbf{B}\), если \(\mathbf{C} \subseteq \mathbf{A}\) и \(\mathbf{D} \subseteq \mathbf{B}\).
\end{center}

\item Два сравнения не пересекаются между собой, если отдельные элементы этих сравнений не пересекаются:

\begin{center}
\(\mathbf{C} \succ \mathbf{D} \cap \mathbf{A} \succ \boldsymbol{B} = \varnothing\), если \(\forall\mathbf{x} \in \mathbf{C}\) и \(\forall\mathbf{y} \in \mathbf{D}\), то имеют место \(\mathbf{x} \notin \mathbf{A}\) и \(\mathbf{y} \notin \mathbf{B}\).
\end{center}

\end{enumerate}

\par 
Когда имеется \emph{m} точных оценок в форме \(\mathbf{x} \succ \mathbf{z}\), то эмпирический функционал риска может быть получен при предположении, что совместная функция распределения \(F(\mathbf{x}, \mathbf{y}, \mathbf{z})\) имеет скачки размером \emph{1/n} в точках \((\mathbf{x_1}, \mathbf{z_1}), (\mathbf{x_2}, \mathbf{z_2}), \dots, (\mathbf{x_n}, \mathbf{z_n})\). 
То есть она является непараметрической функцией распределения. 
Обозначим множество \emph{n} пар \((i, j)\) индексов, соответствующих оценкам \(\mathbf{A_i} \succ \mathbf{B_j}\) как \(\Rho\). 

\par
Введём базовые вероятности неточных оценок. 
Базовая вероятность оценки \(\mathbf{A_i} \succ \mathbf{B_j}\) определяется как \(m(\mathbf{A_i} \succ \mathbf{B_j}) = c_{ij} / n\), где \(c_{ij}\) - это количество оценок \(\mathbf{A_i} \succ \mathbf{B_j}\) в \(\Rho\). 
Далее для краткости предполагается, что \(c_{ij} = 1\) и \(m(\mathbf{A_i} \succ \mathbf{B_j}) = 1/n\) для всех наблюдаемых сравнений. 
Тогда можно записать нижние и верхние границы функционала риска как нижние и верхние границы математические ожидания в рамках теории Демпстера-Шефера

\[
\underline{R}(\mathbf{w}) = \mathbb{\underline{E}}L = \sum \limits_{(i,j) \in \Rho} m(\mathbf{A_i} \succ \mathbf{B_j}) \cdot \underset{%
	\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}%
}{\operatorname{min}} %
L(f(\mathbf{x}, \mathbf{w})) - f(\mathbf{z}, \mathbf{w}))
\]

\[
= \frac{1}{n} \sum \limits_{(i,j) \in \Rho} \underset{%
\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}%
}{\operatorname{min}}%
L(f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})),
\]

\[
\overline{R}(\mathbf{w}) = \mathbb{\overline{E}} L = \sum \limits_{(i,j) \in \Rho} m(\mathbf{A_i} \succ \mathbf{B_j}) \cdot \underset{%
	\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}%
}{\operatorname{max}}
L (f (\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w}))
\]

\[
= \frac{1}{n} \sum \limits_{(i,j) \in \Rho} \underset{%
	\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}%
}{\operatorname{max}}%
L (f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})).
\]

\par
Стоит отметить, что неточная информация в виде неточных оценок сравнений образует множество вероятностных распределений. 
Каждое распределение из множества может быть использовано для вычисления функционала риска.
Однако неявно выбраны два вероятностных распределения, такие, что одно из распределений максимизирует оценку риска для каждого \(\mathbf{w}\), а второе распределение соответственно минизирует оценку риска. 
Выбор вероятностного распределения, максимизирующего оценку риска, может рассматриваться как минимаксная (пессимистичная) стратегия. 
Она может быть достаточно просто объяснена следующим образом. 
``Наихудшее'' распределение, обеспечивающее наибольшее значение функционала риска, должно быть выбрано из множества распределений. 
Критерий минимакса выступает в качестве страховки против наихудшего случая, так как он нацелен на минимизацию ожидаемой потери в наименее благоприятном случае \reference{Robert1994}. 
``Наилучшее'' распределение, обеспечивающее наименьшее значение функционала риска, приводит к миниминной (оптимистичной) стратегии.

%======================================================================================================================

\subsection{Минимаксная стратегия}

\par
Для начала рассмотрим верхнюю границу для оценки риска. 
Наша цель состоит в минимизации верхней оценки риска над множеством параметров \(\mathbf{w}\). 
Для этого введём новые переменные оптимизации \(G_{ij} \in \Rho\) такие, что

\[
G_{ij} = \underset{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}}{\operatorname{max}} L (f (\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})). 
\]

\par
Тогда задача оптимизации может быть переписана как

\[
\overline{R}(\mathbf{w}) = \underset{\mathbf{w}, G_{ij}}{\operatorname{min}} \sum \limits_{(i, j) \in \Rho} G_{ij},
\]

\par
при ограничениях

\[
G_{ij} \geq L (f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})), \forall \mathbf{x} \in \mathbf{A_i}, \forall \mathbf{z} \in \mathbf{B_j}, (i, j) \in \Rho
\]

\par
Здесь \(\mathbf{x}\) и \(\mathbf{z}\) могут быть взяты только из множества \(\Psi\). 

\par
Мы снова используем петлевую функцию потери, определённую на паре объектов \(\mathbf{x} \succ \mathbf{z}\)

\[
L(f, \mathbf{x}, \mathbf{z}) = max (0,1 - f(\mathbf{x}, \mathbf{w}) + f(\mathbf{z}, \mathbf{w})),
\]

\par
и линейную функцию \emph{f}. 
В этом случае можно переписать данную задачу оптимизации в следующем виде: \textcolor{red}{Данная задача уже была переписана в таком виде выше}

\[
\overline{R}(\mathbf{w}) = \underset{\mathbf{w}, G_{ij}}{\operatorname{min}} \sum \limits_{(i, j) \in \Rho} G_{ij},
\]

\par
при ограничениях

\[
G_{ij} + \langle w, \mathbf{x} - \mathbf{z} \rangle \geq 1, \forall \mathbf{x} \in \mathbf{A_i}, \forall \mathbf{z} \in \mathbf{B_j}, 
\]

\[
G_{ij} \succ 0, (i, j) \in \Rho.
\]

\par
Как результат, получена задача линейного программирования, соответствующая минимаксной стратегии. 
Можно увидеть, что данная задача оптимизации отличается от подобных задач, описанных другими авторами, например, \reference{Liu2011}, дополнительными ограничениями для каждой переменной \(G_{ij}\). 

%======================================================================================================================

\subsection{Миниминная стратегия}

\par
Рассмотрим другой ``крайний'' случай, то есть нижнюю границу оценки риска. 
Введём новые переменные оптимизации \(G_{ij} (i, j) \in \Rho\) такие, что

\[
G_{ij} = \underset{\mathbf{x} \ in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}}{\operatorname{min}} L ( f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})). 
\]

\par
Тогда задача оптимизации может быть переписана как

\[
\overline{R}(\mathbf{w}) = \underset{\mathbf{w}, G_{ij}}{\operatorname{min}} \sum \limits_{(i, j) \in \Rho} G_{ij},
\]

\par
при ограничении \textcolor{red}{Точно ли \(G_{ij}\ \geq L\)?}

\[
G_{ij} \geq L ( f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})), \forall \mathbf{x} \in \mathbf{A_i}, \forall \mathbf{z} \in \mathbf{B_j}, (i, j) \in \Rho.
\]

%======================================================================================================================

\section{Формулировка машины опорных векторов при неточных сравнениях}
\label{sec:svm_by_imprecise_comparisons}

\par
Для того чтобы ограничить класс возможных решений задачи классификации и предотвратить переобучение, к целевой функции добавляется стабилизационное или регуляризационное слагаемое \(\Omega[f]\), в частности, \(\Omega[f] = \frac{1}{2}\|w\|^2 = \frac{1}{2} \langle w, w \rangle \). 
Это стандартное регуляризационное слагаемое, которое является наиболее популярным штрафом, или сглаживающим элементом, предложенным Тихоновым \reference{Tikhonov1977}. 
Сглаживающий элемент может рассматриваться как ограничение, которое обеспечивает уникальность с помощью функций штрафа со случайным колебанием и эффективно ограничивающее пространство допустимых решений. 
Детальный анализ регуляризационных методов может быть также найден в работах \reference{Evgeniou2002} \reference{Scholkopf2002}. 

\par
Мы может переписать целевую функцию следующим образом:

\[
\overline{R}(\mathbf{w}) = \frac{1}{2} \langle w, w \rangle + C \sum \limits_{(i, j) \in \Rho} G_{ij}. 
\]

\par
Здесь \emph{C} - это постоянный параметр ``стоимости'', который устанавливает компромисс между минимизацией функционала риска и гладкостью разделяющей функции \reference{Yu2009}. 
Таким образом, исходная задача сводится к задаче квадратичной оптимизации. 

\par
Вместо минимизации целевой функции прямой задачи оптимизации можно записать целевую функцию двойственной задачи, которая называется лагранжианом. 
Причём её седловая точка является оптимумом. 
Лагранжиан представлен в следующем виде:

\[
L = \frac{1}{2} \langle \mathbf{w}, \mathbf{w} \rangle + C \sum \limits_{(i, j) \in \Rho} G_{ij} - \sum \limits_{(i, j) \in \Rho} G_{ij} \eta_{ij}
\]

\[
- \sum \limits_{(i, j) \in \Rho, \mathbf{x} \in \mathbf{A_i}} \sum \limits_{\mathbf{z} \in \mathbf{B_j}} \mu_{ij}(\mathbf{x}, \mathbf{z}) (G_{ij} - 1 + \langle \mathbf{w}, \mathbf{x} - \mathbf{z} \rangle).
\]

\par
Здесь \(\eta_{ij}, \mu_{ij}(\mathbf{x}, \mathbf{z})\) являются множителями Лагранжа. 
Таким образом двойственные переменные должны удовлетворять ограничениям положительности \(\eta_{ij} \geq 0, \mu_{ij} (\mathbf{x}, \mathbf{z}) \geq 0\) для всех \((i, j) \in \Rho\) и соответствующих \(\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}\). 

\par
Седловая точка может быть найдена путём приравнивания производных нулю:

\[
\partial L / \partial w_k = w_k - \sum \limits_{(i, j) \in \Rho} \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z}) \cdot (\mathbf{x}^{(k)} - \mathbf{z}^{(k)}) = 0, k = 1, \dots, l,
\]

\[
\partial L / \partial G_{ij} = C - \eta_{ij} - \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \eta_{ij}(\mathbf{x}, \mathbf{z}) = 0, (i, j) \in \Rho. 
\]

\par
Здесь \(\mathbf{x}^{(k)}\) является \emph{k}-ым элементом вектора \(\mathbf{x}\). 
Путём подстановки \(\eta_{ij}\) из (5) в лагранжиан и дальнейшего упрощения получается:

\[
L = \frac{1}{2} \langle w, w \rangle - \sum \limits_{(i, j) \in \Rho} \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z}) (\langle w, \mathbf{x} - \mathbf{z} \rangle - 1).
\]

\par
После подстановки (4) в лагранжиан можно окончательно получить двойственную задачу оптимизации:

\[
L = \sum \limits_{(i, j) \in \Rho} \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z})
\]

\[
- \sum \limits_{(i, j) \in \Rho} \sum \limits_{(r, t) \in \Rho} \sum \limits_{\mathbf{x_1} \in \mathbf{A_i}, \mathbf{z_1} \in \mathbf{B_j}} \sum \limits_{\mathbf{x_2} \in \mathbf{A_r}, \mathbf{z_2} \in \mathbf{B_t}} \mu_{ij} (\mathbf{x_1}, \mathbf{z_1}) \mu_{rt} (\mathbf{x_2}, \mathbf{z_2}) \cdot \langle \mathbf{x_1} - \mathbf{z_1}, \mathbf{x_2} - \mathbf{z_2} \rangle
\]

\par
при ограничениях

\[
0 \leq \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z}) \leq C, (i, j) \in \Rho.
\]

\par
Условия Каруша-Куна-Такера являются следующими:

\[
\mu_{ij} (\mathbf{x}, \mathbf{z}) (G_{ij} - 1 + \langle w, \mathbf{w} - \mathbf{z} \rangle) = 0,
\]

\[
G_{ij} (C - \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z})) = 0.
\]

\par
Из задачи оптимизации можно увидеть, что она сведена к хорошо известной двойственной задаче квадратичной оптимизации (см. в качестве \reference{Yu2009} для частного случая, когда \(\mathbf{A_i} = \{\mathbf{x_i}\}\) и \(\mathbf{B_i} = \{\mathbf{z_i}\}\)). 

\par
Полученные результаты могут быть применены в пространстве признаков большей размерности, \(\varphi(\mathbf{x})\), для некоторой нелинейной функции \(\varphi\). 
Это достаточно просто получить путём замены скалярных произведений между преобразованными векторами признаков \((\varphi(\mathbf{x_1}) - \varphi(\mathbf{z_1})) (\varphi(\mathbf{x_2}) - \varphi(\mathbf{z_2}))\) при помощи ядра \(K(\mathbf{x_1}, \mathbf{z_1}, \mathbf{x_2}, \mathbf{z_2})\), где (см. \reference{Herbrich2000})

\[
K(\mathbf{x_1}, \mathbf{z_1}, \mathbf{x_2}, \mathbf{z_2}) = K(\mathbf{x_1}, \mathbf{x_2}) - K(\mathbf{x_1}, \mathbf{z_2}) - K(\mathbf{z_1}, \mathbf{x_2}) + K(\mathbf{z_1}, \mathbf{z_2}).
\]

\par
Здесь \(K(\mathbf{x_1}, \mathbf{z_1}, \mathbf{x_2}, \mathbf{z_2})\) является ядром Мерсера. 

%======================================================================================================================

\begin{thebibliography}{9}
	\bibitem{Herbrich2000} R. Herbrich, T. Graepel, K. Obermayer. Large margin rank boundaries for ordinal regression. Smola, Bartlett, Schoelkopf, and Schuurmans, editors, Advances in Large Margin Classifiers, pp. 115–132. MIT Press, Cambridge, MA, 2000%
	\bibitem{Burges2005} C.J. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender. Learning to rank using gradient descent. Proceedings of the 22nd International Conference on Machine Learning (ICML 2005), pp. 89-96, 2005%
	\bibitem{Gao2005} J. Gao, H. Qi, X. Xia, J. Nie. Linear discriminant model for information retrieval. Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2005), pp. 290–297, 2005%
	\bibitem{Shen2005} L. Shen, A.K. Joshi. Ranking and reranking with perceptron. Journal of Machine Learning 60(1–3), pp. 73–96, 2005%
	\bibitem{Freund2003} Y. Freund, R. Iyer, R. Schapire, Y. Singer. An efficient boosting algorithm for combining preferences. Journal of Machine Learning Research 4, pp. 933–969, 2003%
	\bibitem{Joachims2002} T. Joachims. Optimizing search engines using clickthrough data. Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2002), pp. 133–142, 2002%
	\bibitem{Cohen1998} W.W. Cohen, R.E. Schapire, Y. Singer. Learning to order things. Advances in Neural Information Processing Systems (NIPS 1997), vol. 10, pp. 243–270, 1998%
	\bibitem{Tsai2007} M.F. Tsai, T.Y. Liu, T. Qin, H.H. Chen, W.Y. Ma. Frank: a ranking method with fidelity loss. Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2007), pp. 383–390, 2007%
	\bibitem{Zheng2007} Z. Zheng, K. Chen, G. Sun, H. Zha. A regression framework for learning ranking functions using relative relevance judgments. Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2007), pp. 287–294, 2007%
	\bibitem{Zheng2008} Z. Zheng, H. Zha, G. Sun. Query-level learning to rank using isotonic regression. SIGIR 2008 Workshop on Learning to Rank for Information Retrieval (LR4IR 2008), 2008%
	\bibitem{Wolfowitz1942} J. Wolfowitz. Additive partition functions and a class of statistical hypotheses. Annals of Mathematical Statistics, 13(3), pp. 247–279, 1942%
	\bibitem{Liu2011} T.Y. Liu. Learning to Rank for Information Retrieval, Springer, 2011%
	\bibitem{Dempster1967} A.P. Dempster. Upper and lower probabilities induced by a multi-valued mapping. Annales of Mathematical Statistics, 38(2), pp. 325–339, 1967%
	\bibitem{Shafer1976} G. Shafer. A Mathematical Theory of Evidence. Princeton University Press, 1976%
	\bibitem{Halpern1992} J.Y. Halpern, R. Fagin. Two views of belief: Belief as generalized probability and belief as evidence. Artificial Intelligence, 54(3), pp. 275–317, 1992%
	\bibitem{Nguyen1994} H.T. Nguyen,  E.A. Walker. On decision making using belief functions. In R.Y. Yager, M. Fedrizzi, and J. Kacprzyk, editors, Advances in the Dempster-Shafer theory of evidence, pp. 311–330. Wiley, New York, 1994%
	\bibitem{Strat1990} T.M. Strat. Decision analysis using belief functions. International Journal of Approximate Reasoning, 4(5), pp. 391–418, 1990%
	\bibitem{Robert1994} C.P. Robert. The Bayesian Choice. Springer, New York, 1994%
	\bibitem{Tikhonov1977} A.N. Tikhonov, V.Y. Arsenin. Solution of Ill-Posed Problems. W.H. Winston, Washington DC, 1977%
	\bibitem{Evgeniou2002} T. Evgeniou, T. Poggio, M. Pontil, A. Verri. Regularization and statistical learning theory for data analysis. Computational Statistics \& Data Analysis, 38(4), pp. 421–432, 2002%
	\bibitem{Scholkopf2002} B. Scholkopf, A.J. Smola. Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond. The MIT Press, Cambridge, Massachusetts, 2002%
	\bibitem{Yu2009} H. Yu, Y. Kim, S. Hwang. Rv-svm: An efficient method for learning ranking SVM. T. Theeramunkong, B. Kijsirikul, N. Cercone, and T.-B. Ho, editors, Advances in Knowledge Discovery and Data Mining, vol. 5476 of Lecture Notes in Computer Science, pp. 426–438. Springer Berlin / Heidelberg, 2009%
\end{thebibliography}

\end{document}
