% sudo apt-get install texlive-latex-base
% sudo apt-get install texlive-fonts-extra
% sudo apt-get install texlive-latex-recommended
% sudo apt-get install texlive-lang-cyrillic

\documentclass[12pt,a4paper,oneside]{article}

\title{Нечёткий метод опорных векторов}
\author{Л.В. Уткин}
\date{\today}

\usepackage[utf8]{inputenc} % возможность использования Unicode-символов в исходных файлах

\usepackage{amsmath} % для поддержки расширенных математических символов
\usepackage{amsfonts} % для поддержки математических шрифтов
\usepackage{amssymb} % для поддержки расширенных математических символов
\usepackage{datetime} % поддержка календаря и дат
\usepackage{fancyhdr} % использование собственного формата заголовков
\usepackage[T2A]{fontenc} % задание шрифта
\usepackage{geometry} % задания страничных отступов
\usepackage{graphicx} % поддержка PNG-формата в качестве иллюстраций
\usepackage[pdftex,bookmarks,unicode]{hyperref} % поддержка возможности использования ссылок в качестве гиперссылок
\usepackage{setspace} % задание межстрочного интервала
\usepackage{verbatim} % скрытие "comment-окружений" из результирующего документа
\usepackage[english,russian]{babel} % поддержка переносов слов

\hypersetup{
%	bookmarkstype=none,
%	plainpages=false,
	pdftitle={Нечёткий SVM},
	pdfauthor={Игорь Ботян},
	pdfsubject={Статья},
	pdfnewwindow=false,
	pdfkeywords={машина опорных векторов, ранжирование документов, задача классификации},
	colorlinks=true,
	linkcolor=black,
	citecolor=black,
	filecolor=black,
	urlcolor=black,
	pageanchor=false} % если пакет "lastpage" импортирован, то необходимо отключить данную опцию

% задание страничных отступов
\geometry{left=2.5cm}
\geometry{right=2.0cm}
\geometry{top=2.0cm}
\geometry{bottom=2.5cm}

\onehalfspacing % задание полуторного межстрочного интервала
\setlength{\parindent}{25pt} % задание абзацного отступа в 5 символов
\setlength{\headheight}{28pt}

\begin{document}

\input{tex_definitions}
\ApplyCommonPageStyle

%------------------------------------------------------------------------------
% ВВЕДЕНИЕ
%------------------------------------------------------------------------------

\section{Введение}
\label{sec:introduction}

\par
В порядковой регрессии мы рассматриваем проблему, которая имеет свойства, присущие как классификации в целом (i), так и к метрической регрессии (ii). 
Как в (i) $y$ является конечным множеством, так и как в (ii) присутствует упорядочение среди элементов $y$ [4].

% TODO: 
% label - метка
\par
Например, класс \emph{0} может соответствовать понятию ``нерелевантности'', а класс \emph{y\sub{max}}, в свою очередь, может  соответствовать понятию ``наибольшей релевантности''. 
Часто данные классы определяются так называемыми \emph{экспертами}. 
В других случаях они определяются посредством анализа данных перехода по ссылкам между документами (\emph{clickthrough data}).

\par
Попарный подход не направлен на точное предсказывание степени релевантности каждого документа; вместо этого он связан с относительным порядком между двумя документами. 
В этом смысле он ближе к концепции ``ранжирования'', нежели чем к поточечному подходу. 
В поточечном подходе ранжирование обычно сводится к классификации пар документов, то есть к определению, какой из документов в паре является более предпочтительным.
То есть цель обучения заключается в минимизации числа неправильно классифицированных пар документов. 
В крайнем случае, если все пары документов корректно классифицированы, то все документы будут корректно проранжированы. 
Отметим, что такая классификация отличается от классификации, используемой в поточечном подходе, так как она рассматривает каждую пару документов. 
Возникает естественный вопрос, возникающий в случае независимости пар документов, что нарушает основное предположение любой классификации. 
Очевидный факто заключается в том, что пара документов не являются статистически независимыми, что нарушает основное предположение, лежащее в алгоритмах классификации.  
% подход < (инструментарий == фреймворк) < аппарат
Однако принципиально иной теоретический инструментарий необходим для анализа общей характеристики процесса обучения. 
Обсуждения на эту тему будут приведены в Разд. \ref{sec:svm_by_imprecise_comparisons}. 
Существует множество алгоритмов попарного ранжирования, представленных в литературе по методам упорядочивания, и которые основываются на нейронных сетях [8], перцептроне [21, 30], бустинге [18], машине опорных векторов [22, 23] и других методах обучения [12, 33, 36, 37].
В оставшейся части данного раздела будет приведено несколько их примеров. 

\section{Стандартная постановка задачи классификации}
\label{sec:standard_classification_problem}

% problem = задача

\par
Сначала мы рассмотрим стандартную постановку задачи двоичной классификации.
Предположим, что дано множество, называемое обучающей выборкой:

\[
(\mathbf{x_1}, y_1),(\mathbf{x_2}, y_2), \dots, (\mathbf{x_n}, y_n) \in \mathbf{\chi} \times \{-1,+1\}
\]

% pattern = образец наблюдения
% binary = двоичный
% feature = признак
% label = классы

\par
Здесь \(\mathbf{x_1}, \mathbf{x_2}, \dots, \mathbf{x_n}\) является непустым множеством образцов наблюдений или примеров, принимающих значения из множества \(\mathcal{X}\) и имеющие $l$ признаков (характеристик); \(y_1, \dots, y_n\) - классы, или выходные значения, которые могут принимать два значения: \emph{y} = -1 и \emph{y} = 1, соответствующие двум классам. 
Предполагается, что данные, приведённые выше, подчиняются неизвестной функции распределения \(F_0(\mathbf{x}, \emph{y})\) над множеством \(\mathbf{\chi} \times \{-1, +1\}\). 

% decision function = решающая функция

\par
Целью классификации является нахождение решающей функции \(g(\mathbf{x})\), которая точно прогнозирует класс \emph{y}, которому принадлежит некоторый новый пример \(\mathbf{x}\), который в свою очередь может либо принадлежать, либо не принадлежать обучающей выборке. 
Другими словами, мы ищем функцию \emph{g}, минимизирующую ошибку классификации, которая определяется вероятностью условия \(g(x) \neq y\). 
Один из возможных подходов для решения данной задачи является применение так называемой разделяющей функции \(f(\bolsymbol{x}, \mathbf{w})\). 
Эта вещественная функция, знак которой определяет класс: \(g(\mathbf{x})=sgn(f(\mathbf{x}, \mathbf{w}))\).
Она имеет параметры \(\mathbf{w}=(w_0, w_1, \dots, w_n), \mathbf{w} \in \Lambda, w = (w_1, \dots, w_n)\), которые опредляются на основе обучающей выборки посредством алгоритма классификации. 
В частности, функция \(f(\mathbf{x}, \mathbf{w})\) может быть линейной, то есть \(f(\mathbf{x}, \mathbf{w}) = \langle w, \mathbf{x} \rangle + w_0\). 
Обозначим \emph{i}-ый элемент вектора \(\mathbf{x_k}\) как \(x_i^{(k)}\). 

\par
Параметры \(\mathbf{w}\) могут быть найдены посредством минимизации функционала риска по множеству параметров функции \(f(\mathbf{x}, w), w \in \Lambda\):

\[
R(\mathbf{w}) = \int \limits_{\chi \times \{-1, +1\}} L(f, \mathbf{x}, y) \mathrm{d} F_0(\mathbf{x}, y).
\]

Здесь функция потерь \(L(f, \mathbf{x}, y)\) обычно принимает ненулевое значение, когда прогнозируемый при помощи разделяющей функции класс не совпадает с реальным классом \emph{y}, то есть имеет место ошибка классификации. 
В остальных случаях эта ошибка равна нулю. 

\par
Если имеется \emph{n} наблюдений, эмпирический функционал риска определяется путём предположения, что функция \(F_0(\mathbf{x}, y)\) оценивается во рамках аппарата непараметрических методов [13] и имеет скачки размером 1/\emph{n} в точках \(x_1, \dots, x_n\). 
То есть эмпирический функционал риска определяется как

\[
R_{emp}(\mathbf{w}) = n^{-1} \cdot \sum \limits_k=1^n L(f_k, \mathbf{x}_k, y_k)
\]

Здесь \(f_k=f(\mathbf{x_k}, w)\). 

\section{Задача классификации на основе попарного обучения ранжированию}
\label{sec:pairwise_rank_learning_problem}

\par
Так как нашей целью является определение, какой объект в паре является более предпочтительным, то проблема классификации сводится к классификации пар объектов. 
В этом случае мы говорим о попарном подходе. 
В соответствии с данным подходом к решению задачи классификации, сравниваются различные пары \((\mathbf{x},\mathbf{z})\) из множества \emph{M} объектов. 
Здесь \(\mathbf{x}\) и \(\mathbf{z}\) - векторы с \emph{l} вещественнозначными признаками и принимают значения из множества \(\mathbf{\chi}\). 
Мы будем обозначать \(\mathbf{x} \succ \mathbf{z}\), предполагая, что \emph{i}-ый объект более предпочтителен, чем \emph{j}-ый. 
Другими словами, обучающая выборка в попарном подходе состоит из пар объектов как обучающие экземпляры или примеры. 

\par
Для того чтобы рассматривать выходные значения, мы определим две основные идеи попарного ранжирования, которые детально рассмотрены Т.Й. Лиу [?].
Первая из них - это анализ на основе U-статистики.
Она основывается на предположении, что объекты - статистически независимые случайные величины.
Вторая идея основана на анализе средних. 
Она предпологает, что пары объектов также являются статистически независимыми случайными величинами. 
Лиу приводит обоснование обоих идей. 
Ниже будет рассмотрена и использована только вторая. 
В то же время предлагаемый инструментарий может быть применён и к реализации первой идеи аналогичным образом. 

\par
В соответствии с идеей на основе средних [?] каждая пара объектов \((\mathbf{x}, \mathbf{z})\) характеризуется выходной величиной \(y \in \{-1,1\}\), где \emph{y} = 1 означает, что данный объект с признаками \(\mathbf{x}\) является более предпочтительным, чем объект с признаками \(\mathbf{z}\), и \(\mathbf{x} \succ \mathbf{z}\). Если \(y = -1\), то в таком случае \(\mathbf{z} \succ \mathbf{x}\). Тогда предполагается, что \((\mathbf{x}, \mathbf{z}, y)\) является случайной величиной с функцией распределения \(F_1\). Функционал риска в данном случае определяется как

\[
R(\mathbf{w}) = \int \limits_{\chi \times \chi \times \{-1, 1\}} L(f, \mathbf{x}, \mathbf{z}, y) \mathrm{d} F_1(\mathbf{x}, \mathbf{z}, y)
\]

\par
Данный функционал риска означает ожидаемые потери того, что существует некоторая разделяющая функция \emph{f}, которая может неправильно классифицировать случайные пары объектов. 

% judgement = оценка
% relevant = сравнительный
\par
Предположим, что мы имеем какое-то множество \emph{Q} из \emph{n} предпочтений, основывающихся на сравнительных оценках:

\[
Q = \{(\mathbf{x_1}, \mathbf{z_1}, y_1), \mathbf{x_2}, \mathbf{z_2}, y_2), \dots, \mathbf{x_n}, \mathbf{z_n}, y_n)\}
\]

% variable = величина
\par
Задача классификации может быть сформулирована как вычисление ранжирующей функции \emph{f} из какого-то (параметрического) множества \emph{F}, такого, что \(f(\mathbf{x}, \mathbf{w}) \geq f(\mathbf{z}, \mathbf{w})\) при \(\mathbf{x} \succ \mathbf{z}\). 
Если мы предполагаем, что обучающая выборка не может одновременно содержать два элемента \((\mathbf{x}, \mathbf{z}, 1)\) и \((\mathbf{z}, \mathbf{x}, -1)\), то величина \emph{y} для краткости может быть опущена. 

\par
Обычный способ решения такой задачи классификации заключается в рассмотрении эмпирического функционала риска

\[
R_{emp}(\mathbf{w}) = \frac{1}{n} \sum \limits_{i=1}^n L(f_i, \mathbf{x_i}, \mathbf{z_i}).
\]

Теперь задача классификации может быть сформулирована как задача поиска оценочной, или ранжирующей, функции \(f(\mathbf{x}, \mathbf{w})\) (или её параметров \(\mathbf{w}\)), которая минимизирует эмпирический функционал риска, представленный выше. 

\par
Одним из наиболее известных подходов для поиска данной функции \emph{f} является применение метода RankSVM, который строит модель ранжирования путём минимизации регуляризируемого отступа на основе парных потерь. 
Модель RankSVM строится путём минимизации целевой функции [?, ?]

\[
\frac{1}{2} <w, w> + C \cdot \sum \limits_{i=1}^n L(f_i, \mathbf{x_i}, \mathbf{z_i}),
\]

где функция потерь в RankSVM является петлевой функцией, определённой на паре объектов \(\mathbf{x} \succ \mathbf{z}\), то есть она имеет следующий вид:

\[
L(f, \mathbf{x}, \mathbf{z}, y) = max(0, 1 - (f(\mathbf{x}, \mathbf{w}))).
\]

Если мы введём переменные оптимизации \(\xi_i = max(0, 1 - (f(\mathbf{x}, \mathbf{w}))\), то данная задача оптимизации может быть переписана в другом виде:

\[
\frac{1}{2}<w, w> + C \cdot \sum \limits_{i=1}^n \xi_i,
\]

% subject to = при ограничениях
при ограничениях

\[
f(\mathbf{x_i}, w) - f(\mathbf{z_i}, w) \geq 1 - \xi_i, 
\xi_i \geq 0, i = 1, \cdots, n.
\]

Если ранжирующая функция линейна, то мы приходим к задаче квадратичного программирования.

\section{Основные элементы теории Демпстера-Шефера}
\label{sec:dst_definitions}

\par
Пусть \emph{U} - универсальное множество, обычно называемые \emph{фреймом различения} в теории свидетельств. 
Предположим, что было получено \emph{N} наблюдений элемента множества \(u \in U\).
При этом каждое наблюдение получено в результате неточного измерения, приводящего к множеству значений \emph{A}.
Обозначим \(c_i\) как количество появлений множества \(A_i \subseteq U\), а \(\Rho_o(U)\) множеством всех подмножеств \emph{U} (множество мощностей \emph{U}).
Частотная функция \emph{m}, называемая \emph{базовой вероятностью}, может быть определена как [?, ?]:

\[
m : \Rho_o(U) \to [0,1],
m(\varnothing) = 1, \sum \limits_{A \in \Rho_o(U)} m(A) = 1.
\]

\par
Стоит отметить, что область определения базовой вероятности, \(\Rho_o(U)\), отличается от области определения функции плотности, которым является \emph{U}. 
В соответствии с [?], эта функция может быть получена следующим образом:

\[
m(A_i) = c_i / N.
\]

\par
Если \(m(A_i) > 0\), то есть \(A_i\) встречается лишь один раз, то \(A_i\) называется \emph{фокальным элементом}. 

\par
В соответствии с [?], оценки \emph{функции доверия} \(Bel(A)\) и \emph{функции правдоподобия} \(Pl(A)\) для какого-то события \(A \subseteq U\), могут быть определены как

\[
Bel(A) = \sum \limits_{A_i: A_i \subseteq A} m(A_i), 
Pl(A) = \sum \limits_{A_i: A_i \cap \neq \varnothing} m(A_i).
\]

Как было указано в [?], функция доверия может быть формально определена как функция, удовлетворяющая аксиомам, которые могут быть расценены как ослабление аксиом Колмогорова, характеризующие вероятностные функции. 
Поэтому разумно понимать функцию доверия как обобщённую вероятностную функцию [?], а оценки функций доверия \(Bel(A)\) и правдоподобия \(Pl(A)\) могут рассматриваться как нижняя и верхняя границы для вероятности \emph{A}, то есть \(Bel(A) \leq Pr(A) \leq Pl(A)\).

\par
Если существует функция \(h(x)\), то нижнее и верхнее ожидания функции во фреймворке функций доверия могут быть найдены следующим образом [?, ?]:

\[
\mathbb{\overline{E}} h = \sum \limits_{i=1}^N m(A_i) \inf_{x \in A_i} h(x), 
\mathbb{\underline{E}} h = \sum \limits_{i=1}^N m(A_i) \sup_{x \in A_i} h(x).
\]

\section{Формулирование задачи классифкации в терминах неточных сравнений}
\label{sec:classification_problem_by_imprecise_comparisons}

\par
Предположим, что имеется \emph{M} объектов для сравнения \(\mathbf{\Psi} = \{\mathbf{x_1}, \mathbf{x_2}, \dots, \mathbf{x_M}\}\). 
Отсюда следует, что имеется \(N = M(M - 1)\) пар для сравнения. 
Эти \emph{N} пар \((\mathbf{x}, \mathbf{z})\) составляют фрейм различения \(\Omega\) в терминах теории Демпстера-Шефера. 
Предположим, что наши наблюдения или обучающая выборка состоит из \(b \leq N\) оценок вида \(\mathbf{A} \succ \mathbf{B}\), где \(\mathbf{A}\) и \(\mathbf{B}\) - некоторые множества объектов, таких что \(\mathbf{A} \cap \mathbf{B} = \varnothing\).  
Точные оценки \(\mathbf{x} \succ \mathbf{z}\) могут рассматриваться как частный случай неточных, когда множества \(\mathbf{A}\) и \(\mathbf{B}\) состоят из одного элемента. 
Другими словами, мы не можем в общем смысле выделить простые или ``точные'' оценки сравнений вида \(\mathbf{x_i} \succ \mathbf{y_j}\), но мы имеем ``неточные'' оценки \(\mathbf{A} \succ \mathbf{B}\). 
Эти оценки означают, что мы не знаем, как элементы из \(\mathbf{A}\) сравнимы между собой. 
То же самое может быть сказано и о \(\mathbf{B}\). 

\par
Перед дальнейшим рассмотрением этих неточных оценок определим их свойства:

\begin{enumerate}
\item \(\mathbf{C} \succ \mathbf{D} \subseteq \mathbf{A} \succ \mathbf{B}\), если \(\mathbf{C} \subseteq \mathbf{A}\) и \(\mathbf{D} \subseteq \mathbf{B}\).

\item \(\mathbf{C} \succ \mathbf{D} \cap \mathbf{A} \succ \boldsymbol{B} = \varnothing\), если \(\forall\mathbf{x} \in \mathbf{C}\) и \(\forall\mathbf{y} \in \mathbf{D}\), то имеют место \(\mathbf{x} \notin \mathbf{A}\) и \(\mathbf{y} \notin \mathbf{B}\).
\end{enumerate}

% joint = совместная

\par 
Когда мы имеем \emph{m} точных оценок в форме \(\mathbf{x} \succ \mathbf{z}\), то эмпирический функционал риска может быть получен при предположении, что совместная функция распределения \(F(\mathbf{x}, \mathbf{y}, \mathbf{z})\) имеет скачки размером \emph{1/n} в точках \((\mathbf{x_1}, \mathbf{z_1}), (\mathbf{x_2}, \mathbf{z_2}), \dots, (\mathbf{x_n}, \mathbf{z_n})\). 
То есть она является непараметрической функцией распределения. 
Обозначим множество \emph{n} пар \((i, j)\) индексов, соответствующих оценкам \(\mathbf{A_i} \succ \mathbf{B_j}\) как \(\Rho\). 

\par
Введём базовые вероятности неточных оценок. 
Базовая вероятность оценки \(\mathbf{A_i} \succ \mathbf{B_j}\) определяется как \(m(\mathbf{A_i} \succ \mathbf{B_j}) = c_{ij} / n\), где \(c_{ij}\) - это количество оценок \(\mathbf{A_i} \succ \mathbf{B_j}\) в \(\Rho\). 
Далее для краткости предполагается, что \(c_{ij} = 1\) и \(m(\mathbf{A_i} \succ \mathbf{B_j}) = 1/n\) для всех наблюдаемых сравнений. 
Тогда мы можем записать нижние и верхние границы функционалы риска как нижние и верхние границы математические ожидания в рамках теории Демпстера-Шефера

\[
\underline{R}(\mathbf{w}) = \mathbb{\underline{E}}L = \sum \limits_{(i,j) \in \Rho} m(\mathbf{A_i} \succ \mathbf{B_j}) \cdot \underset{%
	\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}%
}{\operatorname{min}} %
L(f(\mathbf{x}, \mathbf{w})) - f(\mathbf{z}, \mathbf{w}))
\]

\[
= \frac{1}{n} \sum \limits_{(i,j) \in \Rho} \underset{%
\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}%
}{\operatorname{min}}%
L(f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})),
\]

\[
\overline{R}(\mathbf{w}) = \mathbb{\overline{E}} L = \sum \limits_{(i,j) \in \Rho} m(\mathbf{A_i} \succ \mathbf{B_j}) \cdot \underset{%
	\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}%
}{\operatorname{max}}
L (f (\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w}))
\]

\[
= \frac{1}{n} \sum \limits_{(i,j) \in \Rho} \underset{%
	\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}%
}{\operatorname{max}}%
L (f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})).
\]

\par
Стоит отметить, что неточная информация в виде неточных оценок сравнений образует множество вероятностных распределений. 
Каждое распределение из множества может быть использовано для вычисления функционала риска.
Однако мы неявно выбрали два вероятностных распределения, такие, что одно из распределений максимизирует оценку риска для каждого \(\mathbf{w}\), а второе распределение соответственно минизирует оценку риска. 
Выбор вероятностного распределения, максимизирующего оценку риска, может рассматриваться как минимаксная (пессимистичная) стратегия. 
Она может быть достаточно просто объяснена следующим образом. 
``Наихудшее'' распределение, обеспечивающее наибольшее значение функционала риска, должно быть выбрано из множества распределений. 
Критерий минимакса выступает в качестве страховки против наихудшего случая, так как он нацелен на минимизацию ожидаемой потери в наименее благоприятном случае [?]. 
``Наилучшее'' распределение, обеспечивающее наименьшее значение функционала риска, приводит к миниминной (оптимистичной) стратегии.

\subsection{Минимаксная стратегия}

\par
Для начала рассмотрим верхнюю границу для оценки риска. 
Наша цель состоит в минимизации верхней оценки риска над множеством параметров \(\mathbf{w}\). 
Для этого введём новые переменные оптимизации \(G_{ij} \in \Rho\) такие, что

\[
G_{ij} = \underset{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}}{\operatorname{max}} L (f (\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})). 
\]

\par
Тогда задача оптимизации может быть переписана как

\[
\overline{R}(\mathbf{w}) = \underset{\mathbf{w}, G_{ij}}{\operatorname{min}} \sum \limits_{(i, j) \in \Rho} G_{ij},
\]

\par
при ограничениях

\[
G_{ij} \geq L (f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})), \forall \mathbf{x} \in \mathbf{A_i}, \forall \mathbf{z} \in \mathbf{B_j}, (i, j) \in \Rho
\]

\par
Здесь \(\mathbf{x}\) и \(\mathbf{z}\) могут быть взяты только из множества \(\Psi\). 

\par
Мы снова используем петлевую функцию потери, определённую на паре объектов \(\mathbf{x} \succ \mathbf{z}\)

\[
L(f, \mathbf{x}, \mathbf{z}) = max (0,1 - f(\mathbf{x}, \mathbf{w}) + f(\mathbf{z}, \mathbf{w})),
\]

\par
и линейную функцию \emph{f}. 
В этом случае мы можем переписать данную задачу оптимизации в следующем виде:

% TODO (2)
\[
\overline{R}(\mathbf{w}) = \underset{\mathbf{w}, G_{ij}}{\operatorname{min}} \sum \limits_{(i, j) \in \Rho} G_{ij},
\]

\par
при ограничениях

\[
G_{ij} + \langle w, \mathbf{x} - \mathbf{z} \rangle \geq 1, \forall \mathbf{x} \in \mathbf{A_i}, \forall \mathbf{z} \in \mathbf{B_j}, 
\]

\[
G_{ij} \succ 0, (i, j) \in \Rho.
\]

\par
Как результат, мы имеем задачу линейного программирования, соответствующую минимаксной стратегии. 
Можно увидеть, что данная задача оптимизации отличается от подобных задач, описанных другими авторами, например, [?], дополнительными ограничениями для каждой переменной \(G_{ij}\). 

\subsection{Миниминная стратегия}

% TODO перевести из новой версии
\par
Рассмотрим другой ``крайний'' случай, то есть нижнюю границу оценки риска. 
Введём новые переменные оптимизации \(G_{ij} (i, j) \in \Rho\) такие, что

\[
G_{ij} = \underset{\mathbf{x} \ in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}}{\operatorname{max}} L ( f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})). 
\]

\par
Тогда задача оптимизации может быть переписана как

\[
\overline{R}(\mathbf{w}) = \underset{\mathbf{w}, G_{ij}}{\operatorname{min}} \sum \limits_{(i, j) \in \Rho} \underset{\mathbf{x} \ in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}}{\operatorname{min}} L ( f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w}))
\]

\par
при ограничении

\[
G_{ij} \geq L ( f(\mathbf{x}, \mathbf{w}) - f(\mathbf{z}, \mathbf{w})), \forall \mathbf{x} \in \mathbf{A_i}, \forall \mathbf{z} \in \mathbf{B_j}, (i, j) \in \Rho.
\]

\section{Формулировка машины опорных векторов при неточных сравнениях}
\label{sec:svm_by_imprecise_comparisons}

\par
Для того чтобы ограничить класс возможных решений задачи классификации и предотвратить переобучение, к целевой функции добавляется стабилизационное или регуляризационное слагаемое \(\Omega[f]\), в частности, \(\Omega[f] = \frac{1}{2}\|w\|^2 = \frac{1}{2} \langle w, w \rangle \). 
Это стандартное регуляризационное слагаемое, которое является наиболее популярным штрафом или сглаживающим элементом, предложенным Тихоновым [?]. 
Сглаживающий элемент может рассматриваться как ограничение, которое обеспечивает уникальность с помощью функций штрафа со случайным колебанием и эффективно ограничивающее пространство допустимых решений. 
Детальный анализ регуляризационных методов может быть также найден в работах [?] [?]. 

\par
% TODO objective function (2)
Мы может переписать целевую функцию следующим образом:

% TODO (3)
\[
\overline{R}(\mathbf{w}) = \frac{1}{2} \langle w, w \rangle + C \sum \limits_{(i, j) \in \Rho} G_{ij}. 
\]

\par
Здесь \emph{C} - это постоянный параметр ``стоимости'', который устанавливает компромисс между минимизацией функционала риска и гладкостью разделяющей функции [?]. 
Таким образом, мы приходим к задаче квадратичной оптимизации. 

\par
Вместо минимизации целевой функции прямой задачи оптимизации можно записать целевую функцию двойственной задачи, которая называется лагранжианом. 
Причём её седловая точка является оптимумом. 
Лагранжиан представлен в следующем виде:

\[
L = \frac{1}{2} \langle \mathbf{w}, \mathbf{w} \rangle + C \sum \limits_{(i, j) \in \Rho} G_{ij} - \sum \limits_{(i, j) \in \Rho} G_{ij} \eta_{ij}
\]

\[
- \sum \limits_{(i, j) \in \Rho, \mathbf{x} \in \mathbf{A_i}} \sum \limits_{\mathbf{z} \in \mathbf{B_j}} \mu_{ij}(\mathbf{x}, \mathbf{z}) (G_{ij} - 1 + \langle \mathbf{w}, \mathbf{x} - \mathbf{z} \rangle).
\]

\par
Здесь \(\eta_{ij}, \mu_{ij}(\mathbf{x}, \mathbf{z})\) являются множителями Лагранжа. 
Таким образом двойственные переменные должны удовлетворять ограничениям положительности \(\eta_{ij} \geq 0, \mu_{ij} (\mathbf{x}, \mathbf{z}) \geq 0\) для всех \((i, j) \in \Rho\) и соответствующих \(\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}\). 

\par
Седловая точка может быть найдена путём приравнивания производных нулю:

% TODO (4)
\[
\partial L / \partial w_k = w_k - \sum \limits_{(i, j) \in \Rho} \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z}) \cdot (\mathbf{x}^{(k)} - \mathbf{z}^{(k)}) = 0, k = 1, \dots, l,
\]

% TODO (5)
\[
\partial L / \partial G_{ij} = C - \eta_{ij} - \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \eta_{ij}(\mathbf{x}, \mathbf{z}) = 0, (i, j) \in \Rho. 
\]

\par
Здесь \(\mathbf{x}^{(k)}\) является \emph{k}-ым элементом вектора \(\mathbf{x}\). 
Путём подставновки \(\eta_{ij}\) из (5) в лагранжиан и дальнейшего упрощения мы получаем:

\[
L = \frac{1}{2} \langle w, w \rangle - \sum \limits_{(i, j) \in \Rho} \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z}) (\langle w, \mathbf{x} - \mathbf{z} \rangle - 1).
\]

\par
После подстановки (4) в лагранжиан мы окончательно получаем двойственную задачу оптимизации:

\[
L = \sum \limits_{(i, j) \in \Rho} \sum \limits_{\mathbf{x} \in \mathbf{A_j}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z})
\]

\[
- \sum \limits_{(i, j) \in \Rho} \sum \limits_{(r, t) \in \Rho} \sum \limits_{\mathbf{x_1} \in \mathbf{A_i}, \mathbf{z_1} \in \mathbf{B_j}} \sum \limits_{\mathbf{x_2} \in \mathbf{A_r}, \mathbf{z_2} \in \mathbf{B_t}} \mu_{ij} (\mathbf{x_1}, \mathbf{z_1}) \mu_{rt} (\mathbf{x_2}, \mathbf{z_2}) \cdot \langle \mathbf{x_1} - \mathbf{z_1}, \mathbf{x_2} - \mathbf{z_2} \rangle
\]

\par
при ограничениях

\[
0 \leq \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z}) \leq C, (i, j) \in \Rho.
\]

\par
Условия Каруша-Куна-Такера являются следующими:

\[
\mu_{ij} (\mathbf{x}, \mathbf{z}) (G_{ij} - 1 + \langle w, \mathbf{w} - \mathbf{z} \rangle) = 0,
\]

\[
G_{ij} (C - \sum \limits_{\mathbf{x} \in \mathbf{A_i}, \mathbf{z} \in \mathbf{B_j}} \mu_{ij} (\mathbf{x}, \mathbf{z})) = 0.
\]

\par
Из задачи оптимизации можно увидеть, что она сведена к хорошо известной двойственной задаче квадратичной оптимизации (см. в качестве [?] для частного случая, когда \(\mathbf{A_i} = \{\mathbf{x_i}\}\) и \(\mathbf{B_i} = \{\mathbf{z_i}\}\)). 

\par
Полученные результаты могут быть применены в пространстве признаков большей размерности, \(\varphi(\mathbf{x})\), для некоторой нелинейной функции \(\varphi\). 
Это достаточно просто получить путём замены скалярных произведений между преобразованными векторами признаков \((\varphi(\mathbf{x_1}) - \varphi(\mathbf{z_1})) (\varphi(\mathbf{x_2}) - \varphi(\mathbf{z_2}))\) при помощи ядра \(K(\mathbf{x_1}, \mathbf{z_1}, \mathbf{x_2}, \mathbf{z_2})\), где (см. [?])

\[
K(\mathbf{x_1}, \mathbf{z_1}, \mathbf{x_2}, \mathbf{z_2}) = K(\mathbf{x_1}, \mathbf{x_2}) - K(\mathbf{x_1}, \mathbf{z_2}) - K(\mathbf{z_1}, \mathbf{x_2}) + K(\mathbf{z_1}, \mathbf{z_2}).
\]

\par
Здесь \(K(\mathbf{x_1}, \mathbf{z_1}, \mathbf{x_2}, \mathbf{z_2})\) является ядром Мерсера. 

% задачи следующие:
% 1) написать нормальное введение (на 1-2 страницы, макс. 3) для уже сделанных результатов. нужно написать как раз о том, как дальше будет организована статья. кратенький обзор RankSVM и других сущ. методов (их суть), словами, не формулами. указать, что теперь множество пар документов, а не просто документов. пояснить, что такое разделяющая функция, которую мы получили. что от от неё ждать. нужно обязательно указать примеры, где это может применяться. откуда берётся ситуация неточных данных. 
% важно с точки зрения понимания поставить задачу своими словами
% набиваем язык с помощью его написания
% 2) обязательно нужно написать заключение (0,5 - 1 страница). указать, что наша задача - не показать, что предлагаемый метод лучше или хуже (так как нет сравнений), (! можно указать remark). главное - объяснить, почему не делали численных расчётов. но наш главный результат - сама постановка задачи и сведение к классической SVM. не столько улучшающий метод, сколько сводящийся к классической SVM. 
% основные идеи: почему мы не ставили численных эксперимент + то, что сделано (основной полученный результат, идея)
% 3) abstract (аннотация)
% 4) содержание представлено в этом файле
% 5) можно добавить пояснения в статье - это очень приветствуется

% вторая статья - взглянуть на эту проблему с другой стороны. взять пример из предметной области. намного меньше математики. показать на этом примере представленные выше идеи. Всё с практической точки зрения. на хабрахабре дан пример из предметной области документооборота. 

\end{document}
